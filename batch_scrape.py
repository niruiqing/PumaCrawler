#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡çˆ¬å–Pumaå•†å“ä¿¡æ¯ç¤ºä¾‹
"""

import subprocess
import time
import json
from datetime import datetime

def batch_scrape_puma():
    """æ‰¹é‡çˆ¬å–å¤šä¸ªPumaå•†å“"""
    
    # å•†å“URLåˆ—è¡¨
    urls = [
        "https://us.puma.com/us/en/pd/evospeed-mid-distance-nitro-elite-3-track--field-distance-spikes/312637?swatch=01",
        # å¯ä»¥æ·»åŠ æ›´å¤šPumaå•†å“URL
    ]
    
    results = []
    
    print(f"ğŸš€ å¼€å§‹æ‰¹é‡çˆ¬å– {len(urls)} ä¸ªå•†å“...")
    
    for i, url in enumerate(urls, 1):
        print(f"\nğŸ“¦ æ­£åœ¨çˆ¬å–ç¬¬ {i}/{len(urls)} ä¸ªå•†å“...")
        print(f"ğŸ”— URL: {url}")
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        output_file = f"batch_product_{i}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        try:
            # è°ƒç”¨puma_crawler.py
            result = subprocess.run([
                'python', 'puma_crawler.py',
                '--url', url,
                '--method', 'enhanced',
                '--output', output_file
            ], capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0:
                print(f"âœ… æˆåŠŸçˆ¬å–å¹¶ä¿å­˜åˆ°: {output_file}")
                
                # è¯»å–ç»“æœ
                try:
                    with open(output_file, 'r', encoding='utf-8') as f:
                        product_data = json.load(f)
                        results.append(product_data)
                except:
                    pass
            else:
                print(f"âŒ çˆ¬å–å¤±è´¥: {result.stderr}")
                
        except subprocess.TimeoutExpired:
            print("â° çˆ¬å–è¶…æ—¶")
        except Exception as e:
            print(f"âŒ æ‰§è¡Œé”™è¯¯: {e}")
        
        # æ·»åŠ å»¶è¿Ÿé¿å…è¢«å°IP
        if i < len(urls):
            print("â³ ç­‰å¾…3ç§’...")
            time.sleep(3)
    
    print(f"\nğŸ‰ æ‰¹é‡çˆ¬å–å®Œæˆï¼æˆåŠŸè·å– {len(results)} ä¸ªå•†å“ä¿¡æ¯")
    
    # æ±‡æ€»ç»“æœ
    if results:
        summary_file = f"batch_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“Š æ±‡æ€»æ–‡ä»¶å·²ä¿å­˜: {summary_file}")

if __name__ == "__main__":
    batch_scrape_puma()