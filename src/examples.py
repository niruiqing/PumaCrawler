#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Pumaå•†å“ä¿¡æ¯çˆ¬è™«ä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºä¸åŒçš„ä½¿ç”¨åœºæ™¯å’Œæ–¹æ³•
"""

import json
from puma_crawler import main as crawler_main
from enhanced_puma_scraper import enhanced_scrape_puma
import sys
import os

def example_1_basic_usage():
    """ç¤ºä¾‹1: åŸºæœ¬ç”¨æ³•"""
    print("=" * 60)
    print("ç¤ºä¾‹1: åŸºæœ¬ç”¨æ³• - ä½¿ç”¨é»˜è®¤URLå’Œè‡ªåŠ¨æ¨¡å¼")
    print("=" * 60)
    
    # æ¨¡æ‹Ÿå‘½ä»¤è¡Œå‚æ•°
    original_argv = sys.argv
    sys.argv = ['puma_crawler.py', '--method', 'auto']
    
    try:
        result = crawler_main()
        return result
    except SystemExit:
        pass
    finally:
        sys.argv = original_argv

def example_2_custom_url():
    """ç¤ºä¾‹2: è‡ªå®šä¹‰URL"""
    print("\\n" + "=" * 60)
    print("ç¤ºä¾‹2: è‡ªå®šä¹‰URLçˆ¬å–")
    print("=" * 60)
    
    # å…¶ä»–Pumaå•†å“URLç¤ºä¾‹
    url = "https://us.puma.com/us/en/pd/evospeed-mid-distance-nitro-elite-3-track--field-distance-spikes/312637?swatch=01"
    
    print(f"çˆ¬å–URL: {url}")
    
    # ä½¿ç”¨å¢å¼ºç‰ˆçˆ¬è™«
    result = enhanced_scrape_puma(url)
    
    if result:
        print(f"âœ… æˆåŠŸè·å–å•†å“: {result.get('name', 'N/A')}")
        print(f"ğŸ’° ä»·æ ¼: {result.get('currency', 'USD')} ${result.get('price', 'N/A')}")
        return result
    else:
        print("âŒ çˆ¬å–å¤±è´¥")
        return None

def example_3_batch_scraping():
    """ç¤ºä¾‹3: æ‰¹é‡çˆ¬å–ï¼ˆæ¼”ç¤ºæ¦‚å¿µï¼‰"""
    print("\\n" + "=" * 60)
    print("ç¤ºä¾‹3: æ‰¹é‡çˆ¬å–æ¦‚å¿µæ¼”ç¤º")
    print("=" * 60)
    
    # æ³¨æ„ï¼šå®é™…ä½¿ç”¨æ—¶è¯·éµå®ˆç½‘ç«™çš„robots.txtå’Œä½¿ç”¨æ¡æ¬¾
    # è¿™é‡Œåªæ˜¯æ¼”ç¤ºæ¦‚å¿µï¼Œå®é™…æ‰¹é‡çˆ¬å–éœ€è¦æ·»åŠ åˆé€‚çš„å»¶è¿Ÿ
    
    urls = [
        "https://us.puma.com/us/en/pd/evospeed-mid-distance-nitro-elite-3-track--field-distance-spikes/312637?swatch=01",
        # å¯ä»¥æ·»åŠ æ›´å¤šURL
    ]
    
    results = []
    
    for i, url in enumerate(urls, 1):
        print(f"\\næ­£åœ¨çˆ¬å–ç¬¬ {i} ä¸ªå•†å“...")
        print(f"URL: {url}")
        
        try:
            result = enhanced_scrape_puma(url)
            if result:
                results.append(result)
                print(f"âœ… æˆåŠŸ: {result.get('name', 'N/A')}")
            else:
                print("âŒ å¤±è´¥")
                
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
        
        # åœ¨å®é™…æ‰¹é‡çˆ¬å–ä¸­ï¼Œåº”è¯¥æ·»åŠ å»¶è¿Ÿä»¥é¿å…è¢«å°IP
        # import time
        # time.sleep(2)  # å»¶è¿Ÿ2ç§’
    
    print(f"\\næ‰¹é‡çˆ¬å–å®Œæˆï¼ŒæˆåŠŸè·å– {len(results)} ä¸ªå•†å“ä¿¡æ¯")
    return results

def example_4_data_analysis():
    """ç¤ºä¾‹4: æ•°æ®åˆ†æ"""
    print("\\n" + "=" * 60)
    print("ç¤ºä¾‹4: ç®€å•æ•°æ®åˆ†æ")
    print("=" * 60)
    
    # è¯»å–ä¹‹å‰ä¿å­˜çš„JSONæ–‡ä»¶
    json_files = [f for f in os.listdir('.') if f.endswith('.json') and 'puma' in f]
    
    if not json_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å•†å“æ•°æ®æ–‡ä»¶")
        return
    
    products = []
    for file in json_files:
        try:
            with open(file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if data.get('name'):
                    products.append(data)
        except:
            continue
    
    if not products:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å•†å“æ•°æ®")
        return
    
    print(f"ğŸ“Š åˆ†æ {len(products)} ä¸ªå•†å“æ•°æ®:")
    
    # ä»·æ ¼åˆ†æ
    prices = []
    for product in products:
        price = product.get('price', '')
        if price and price.replace('.', '').isdigit():
            prices.append(float(price))
    
    if prices:
        print(f"ğŸ’° ä»·æ ¼ç»Ÿè®¡:")
        print(f"   å¹³å‡ä»·æ ¼: ${sum(prices)/len(prices):.2f}")
        print(f"   æœ€é«˜ä»·æ ¼: ${max(prices):.2f}")
        print(f"   æœ€ä½ä»·æ ¼: ${min(prices):.2f}")
    
    # å“ç‰Œç»Ÿè®¡
    brands = {}
    for product in products:
        brand = product.get('brand', 'Unknown')
        brands[brand] = brands.get(brand, 0) + 1
    
    print(f"ğŸ·ï¸  å“ç‰Œç»Ÿè®¡:")
    for brand, count in brands.items():
        print(f"   {brand}: {count} ä¸ªå•†å“")
    
    # æè¿°é•¿åº¦åˆ†æ
    desc_lengths = []
    for product in products:
        desc = product.get('description', '')
        if desc:
            desc_lengths.append(len(desc))
    
    if desc_lengths:
        print(f"ğŸ“ æè¿°ç»Ÿè®¡:")
        print(f"   å¹³å‡æè¿°é•¿åº¦: {sum(desc_lengths)/len(desc_lengths):.0f} å­—ç¬¦")
        print(f"   æœ€é•¿æè¿°: {max(desc_lengths)} å­—ç¬¦")
        print(f"   æœ€çŸ­æè¿°: {min(desc_lengths)} å­—ç¬¦")

def example_5_export_csv():
    """ç¤ºä¾‹5: å¯¼å‡ºä¸ºCSVæ ¼å¼"""
    print("\\n" + "=" * 60)
    print("ç¤ºä¾‹5: å¯¼å‡ºCSVæ ¼å¼")
    print("=" * 60)
    
    try:
        import csv
        
        # è¯»å–JSONæ•°æ®
        json_files = [f for f in os.listdir('.') if f.endswith('.json') and 'puma' in f]
        
        if not json_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å•†å“æ•°æ®æ–‡ä»¶")
            return
        
        products = []
        for file in json_files:
            try:
                with open(file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if data.get('name'):
                        products.append(data)
            except:
                continue
        
        if not products:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å•†å“æ•°æ®")
            return
        
        # å®šä¹‰CSVå­—æ®µ
        fieldnames = ['name', 'brand', 'price', 'currency', 'color', 'product_id', 'description', 'url']
        
        csv_filename = 'puma_products.csv'
        
        with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            
            for product in products:
                row = {}
                for field in fieldnames:
                    value = product.get(field, '')
                    # å¤„ç†æè¿°å­—æ®µï¼Œé™åˆ¶é•¿åº¦
                    if field == 'description' and value:
                        value = value[:200] + '...' if len(value) > 200 else value
                    row[field] = value
                writer.writerow(row)
        
        print(f"âœ… CSVæ–‡ä»¶å·²å¯¼å‡º: {csv_filename}")
        print(f"ğŸ“Š åŒ…å« {len(products)} ä¸ªå•†å“")
        
    except ImportError:
        print("âŒ CSVæ¨¡å—ä¸å¯ç”¨")
    except Exception as e:
        print(f"âŒ å¯¼å‡ºCSVå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•° - è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("ğŸš€ Pumaå•†å“ä¿¡æ¯çˆ¬è™«ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    try:
        # ç¤ºä¾‹1: åŸºæœ¬ç”¨æ³•
        example_1_basic_usage()
        
        # ç¤ºä¾‹2: è‡ªå®šä¹‰URL
        example_2_custom_url()
        
        # ç¤ºä¾‹3: æ‰¹é‡çˆ¬å–
        example_3_batch_scraping()
        
        # ç¤ºä¾‹4: æ•°æ®åˆ†æ
        example_4_data_analysis()
        
        # ç¤ºä¾‹5: å¯¼å‡ºCSV
        example_5_export_csv()
        
        print("\\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆ!")
        
    except KeyboardInterrupt:
        print("\\nâŒ ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\\nâŒ è¿è¡Œå‡ºé”™: {e}")

if __name__ == "__main__":
    main()