#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Pumaå•†å“é¡µé¢å›¾ç‰‡åˆ†æå™¨
åˆ†æé¡µé¢ä¸­çš„æ‰€æœ‰å›¾ç‰‡å…ƒç´ ï¼Œæ‰¾å‡ºå•†å“å›¾ç‰‡çš„ä½ç½®
"""

import requests
from bs4 import BeautifulSoup
import json
import re
from urllib.parse import urljoin

def analyze_images(url):
    """åˆ†æé¡µé¢ä¸­çš„æ‰€æœ‰å›¾ç‰‡"""
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
    }
    
    try:
        print(f"ğŸ” åˆ†æé¡µé¢å›¾ç‰‡: {url}")
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        print("âœ… é¡µé¢è·å–æˆåŠŸï¼Œå¼€å§‹åˆ†æå›¾ç‰‡...")
        
        # æ‰¾åˆ°æ‰€æœ‰imgæ ‡ç­¾
        all_images = soup.find_all('img')
        print(f"ğŸ“Š é¡µé¢æ€»å…±æ‰¾åˆ° {len(all_images)} ä¸ªå›¾ç‰‡æ ‡ç­¾")
        
        # åˆ†æå›¾ç‰‡
        product_images = []
        other_images = []
        
        for i, img in enumerate(all_images, 1):
            img_info = {
                'index': i,
                'src': img.get('src', ''),
                'data_src': img.get('data-src', ''),
                'data_lazy_src': img.get('data-lazy-src', ''),
                'alt': img.get('alt', ''),
                'class': img.get('class', []),
                'id': img.get('id', ''),
                'parent_class': img.parent.get('class', []) if img.parent else [],
                'parent_id': img.parent.get('id', '') if img.parent else '',
                'style': img.get('style', '')
            }
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºå•†å“å›¾ç‰‡
            is_product_img = False
            
            # æ£€æŸ¥srcå±æ€§
            for src_attr in ['src', 'data_src', 'data_lazy_src']:
                src_value = img_info.get(src_attr, '')
                if src_value:
                    # è¿‡æ»¤æ¡ä»¶
                    if any(keyword in src_value.lower() for keyword in [
                        'product', 'zoom', 'detail', 'carousel', 'gallery'
                    ]):
                        is_product_img = True
                        break
                    
                    # æ£€æŸ¥å›¾ç‰‡å°ºå¯¸ï¼ˆé€šå¸¸å•†å“å›¾ç‰‡æ¯”è¾ƒå¤§ï¼‰
                    if any(size in src_value for size in ['800', '600', '1000', '1200']):
                        is_product_img = True
                        break
            
            # æ£€æŸ¥altå±æ€§
            alt_text = img_info.get('alt', '').lower()
            if any(keyword in alt_text for keyword in [
                'product', 'shoe', 'sneaker', 'puma', 'evospeed', 'nitro'
            ]):
                is_product_img = True
            
            # æ£€æŸ¥classå±æ€§
            class_list = img_info.get('class', [])
            if any(cls for cls in class_list if any(keyword in cls.lower() for keyword in [
                'product', 'carousel', 'gallery', 'zoom', 'detail'
            ])):
                is_product_img = True
            
            # æ£€æŸ¥çˆ¶å…ƒç´ class
            parent_class = img_info.get('parent_class', [])
            if any(cls for cls in parent_class if any(keyword in cls.lower() for keyword in [
                'product', 'carousel', 'gallery', 'zoom', 'detail', 'images'
            ])):
                is_product_img = True
            
            if is_product_img:
                product_images.append(img_info)
            else:
                other_images.append(img_info)
        
        print(f"âœ… åˆ†æå®Œæˆ:")
        print(f"   ğŸ–¼ï¸  ç–‘ä¼¼å•†å“å›¾ç‰‡: {len(product_images)} ä¸ª")
        print(f"   ğŸ–¼ï¸  å…¶ä»–å›¾ç‰‡: {len(other_images)} ä¸ª")
        
        # æ˜¾ç¤ºå•†å“å›¾ç‰‡è¯¦æƒ…
        if product_images:
            print(f"\nğŸ“‹ ç–‘ä¼¼å•†å“å›¾ç‰‡è¯¦æƒ…:")
            for img in product_images[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                print(f"\nå›¾ç‰‡ #{img['index']}:")
                print(f"  src: {img['src']}")
                if img['data_src']:
                    print(f"  data-src: {img['data_src']}")
                if img['data_lazy_src']:
                    print(f"  data-lazy-src: {img['data_lazy_src']}")
                print(f"  alt: {img['alt']}")
                print(f"  class: {img['class']}")
                print(f"  parent_class: {img['parent_class']}")
        
        # åˆ†æé¡µé¢çš„scriptæ ‡ç­¾ï¼Œå¯»æ‰¾å›¾ç‰‡æ•°æ®
        print(f"\nğŸ” åˆ†æJavaScriptä¸­çš„å›¾ç‰‡æ•°æ®...")
        script_tags = soup.find_all('script')
        
        image_urls_in_js = []
        for script in script_tags:
            if script.string:
                # æŸ¥æ‰¾å›¾ç‰‡URLæ¨¡å¼
                img_patterns = [
                    r'"(https?://[^"]*\.(jpg|jpeg|png|webp)[^"]*)"',
                    r"'(https?://[^']*\.(jpg|jpeg|png|webp)[^']*)'",
                    r'"(/[^"]*\.(jpg|jpeg|png|webp)[^"]*)"',
                    r"'(/[^']*\.(jpg|jpeg|png|webp)[^']*)'",
                ]
                
                for pattern in img_patterns:
                    matches = re.findall(pattern, script.string, re.IGNORECASE)
                    for match in matches:
                        url_part = match[0] if isinstance(match, tuple) else match
                        if url_part not in image_urls_in_js:
                            image_urls_in_js.append(url_part)
        
        print(f"ğŸ“Š åœ¨JavaScriptä¸­æ‰¾åˆ° {len(image_urls_in_js)} ä¸ªå›¾ç‰‡URL")
        
        # è¿‡æ»¤å‡ºå¯èƒ½çš„å•†å“å›¾ç‰‡
        js_product_images = []
        for img_url in image_urls_in_js:
            if any(keyword in img_url.lower() for keyword in [
                'product', 'zoom', 'detail', '312637', 'evospeed'
            ]):
                # æ„å»ºå®Œæ•´URL
                if img_url.startswith('//'):
                    full_url = 'https:' + img_url
                elif img_url.startswith('/'):
                    full_url = 'https://us.puma.com' + img_url
                elif not img_url.startswith('http'):
                    full_url = urljoin('https://us.puma.com', img_url)
                else:
                    full_url = img_url
                
                if full_url not in js_product_images:
                    js_product_images.append(full_url)
        
        if js_product_images:
            print(f"\nğŸ–¼ï¸  JavaScriptä¸­çš„å•†å“å›¾ç‰‡ ({len(js_product_images)} ä¸ª):")
            for i, img_url in enumerate(js_product_images[:10], 1):
                print(f"  {i}. {img_url}")
        
        # åˆå¹¶æ‰€æœ‰æ‰¾åˆ°çš„å›¾ç‰‡
        all_found_images = []
        
        # ä»HTML imgæ ‡ç­¾è·å–
        for img in product_images:
            for attr in ['src', 'data_src', 'data_lazy_src']:
                url_val = img.get(attr, '')
                if url_val:
                    # æ„å»ºå®Œæ•´URL
                    if url_val.startswith('//'):
                        full_url = 'https:' + url_val
                    elif url_val.startswith('/'):
                        full_url = 'https://us.puma.com' + url_val
                    elif not url_val.startswith('http'):
                        full_url = urljoin('https://us.puma.com', url_val)
                    else:
                        full_url = url_val
                    
                    if full_url not in all_found_images:
                        all_found_images.append(full_url)
        
        # ä»JavaScriptè·å–
        all_found_images.extend(js_product_images)
        
        # å»é‡
        all_found_images = list(set(all_found_images))
        
        print(f"\nğŸ¯ æœ€ç»ˆæ‰¾åˆ°çš„å•†å“å›¾ç‰‡ ({len(all_found_images)} ä¸ª):")
        for i, img_url in enumerate(all_found_images[:15], 1):
            print(f"  {i}. {img_url}")
        
        return all_found_images
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        return []

def main():
    """ä¸»å‡½æ•°"""
    url = "https://us.puma.com/us/en/pd/evospeed-mid-distance-nitro-elite-3-track--field-distance-spikes/312637?swatch=01"
    
    images = analyze_images(url)
    
    if images:
        # ä¿å­˜åˆ†æç»“æœ
        result = {
            'url': url,
            'images_found': len(images),
            'images': images,
            'analysis_time': '2025-08-22'
        }
        
        with open('image_analysis_result.json', 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… åˆ†æç»“æœå·²ä¿å­˜åˆ°: image_analysis_result.json")
    else:
        print("\nâŒ æœªæ‰¾åˆ°ä»»ä½•å•†å“å›¾ç‰‡")

if __name__ == "__main__":
    main()