#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–°çš„PUMA GraphQL APIå®¢æˆ·ç«¯
åŸºäºå®é™…çš„curlè¯·æ±‚å‚æ•°é‡æ–°å®ç°ï¼Œè·å–è¯¦ç»†çš„å•†å“ä¿¡æ¯
"""

import requests
import json
import re
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict, field

@dataclass
class ProductInfo:
    """å•†å“ä¿¡æ¯æ•°æ®ç±»"""
    # åŸºæœ¬ä¿¡æ¯
    name: str = ""
    header: str = ""
    sub_header: str = ""
    brand: str = ""
    product_id: str = ""
    variant_id: str = ""
    sku: str = ""
    style_number: str = ""
    ean: str = ""
    
    # åˆ†ç±»ä¿¡æ¯
    category: str = ""
    subcategory: str = ""
    product_division: str = ""
    primary_category_id: str = ""
    gender: str = ""
    age_group: str = ""
    
    # å¯¼èˆªä¿¡æ¯ï¼ˆé¢åŒ…å±‘å¯¼èˆªï¼‰
    breadcrumb: List[Dict[str, str]] = field(default_factory=list)
    navigation_path: str = ""
    
    # ä»·æ ¼ä¿¡æ¯
    price: float = 0.0
    original_price: float = 0.0
    sale_price: float = 0.0
    promotion_price: Optional[float] = None
    best_price: Optional[float] = None
    discount: float = 0.0
    tax: float = 0.0
    tax_rate: float = 0.0
    
    # é¢œè‰²ä¿¡æ¯
    color: str = ""
    color_name: str = ""
    color_value: str = ""
    color_code: str = ""
    
    # æè¿°å’Œç‰¹æ€§
    description: str = ""
    features: List[str] = field(default_factory=list)
    tech_specs: Dict[str, Any] = field(default_factory=dict)
    
    # ææ–™å’ŒæŠ¤ç†
    materials: List[str] = field(default_factory=list)
    material_composition: List[str] = field(default_factory=list)
    care_instructions: List[str] = field(default_factory=list)
    
    # å›¾ç‰‡ä¿¡æ¯
    images: List[str] = field(default_factory=list)
    preview_image: str = ""
    vertical_images: List[str] = field(default_factory=list)
    
    # å°ºç ä¿¡æ¯
    sizes: List[str] = field(default_factory=list)
    available_sizes: List[str] = field(default_factory=list)
    unavailable_sizes: List[str] = field(default_factory=list)
    size_chart_id: str = ""
    
    # æ–°å¢ï¼šè¯¦ç»†å°ºç ä¿¡æ¯
    size_groups: List[Dict] = field(default_factory=list)
    product_measurements: Dict[str, Any] = field(default_factory=dict)
    metric_measurements: List[List[str]] = field(default_factory=list)
    imperial_measurements: List[List[str]] = field(default_factory=list)
    
    # åº“å­˜å’ŒçŠ¶æ€
    orderable: bool = True
    availability: str = ""
    stock_status: str = ""
    display_out_of_stock: Optional[Dict] = None
    is_final_sale: Optional[bool] = None
    
    # è¯„ä»·ä¿¡æ¯
    rating: Optional[float] = None
    reviews_count: Optional[int] = None
    disable_ratings: Optional[bool] = None
    disable_reviews: Optional[bool] = None
    
    # ä¿ƒé”€å’Œå¾½ç« 
    badges: List[str] = field(default_factory=list)
    promotions: List[Dict] = field(default_factory=list)
    promotion_exclusion: bool = False
    percentage_discount_badge: int = 0
    
    # åˆ¶é€ ä¿¡æ¯
    manufacturer_info: Dict[str, Any] = field(default_factory=dict)
    country_of_origin: str = ""
    
    # å…¶ä»–ä¿¡æ¯
    valid_until: str = ""
    is_app_exclusive: bool = False
    app_only_date_time_from: Optional[str] = None
    app_only_date_time_to: Optional[str] = None
    special_message: Optional[str] = None
    model_measurement_text: Optional[str] = None
    
    # å…ƒæ•°æ®
    scraped_at: str = ""
    method: str = "new_graphql"
    url: str = ""



class NewPumaGraphQLAPI:
    """æ–°çš„PUMA GraphQL APIå®¢æˆ·ç«¯"""
    
    def __init__(self):
        """åˆå§‹åŒ–APIå®¢æˆ·ç«¯"""
        self.base_url = "https://us.puma.com/api/graphql"
        self.session = requests.Session()
        
        # åŸºç¡€è¯·æ±‚å¤´ï¼ˆåŸºäºæä¾›çš„curlè¯·æ±‚ï¼‰
        self.headers = {
            "accept": "application/graphql-response+json, application/graphql+json, application/json",
            "accept-language": "zh-CN,zh;q=0.9",
            "content-type": "application/json",
            "locale": "en-US",
            "origin": "https://us.puma.com",
            "priority": "u=1, i",
            "puma-request-source": "web",
            "sec-ch-ua": '"Not;A=Brand";v="99", "Google Chrome";v="139", "Chromium";v="139"',
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": '"Windows"',
            "sec-fetch-dest": "empty",
            "sec-fetch-mode": "cors",
            "sec-fetch-site": "same-origin",
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36",
            "x-graphql-client-name": "nitro-fe",
            "x-graphql-client-version": "961757de4b96db7c1c36770d26de3e4fb6f16f24",
            "x-operation-name": "PDP"
        }
        
        # ä»é¡¹ç›®ä¸­å·²æœ‰çš„æœ‰æ•ˆtokenï¼ˆæ¥è‡ªcomplete_graphql_api.pyï¼‰
        self.auth_headers = {
            "authorization": "Bearer eyJ2ZXIiOiIxLjAiLCJqa3UiOiJzbGFzL3Byb2QvYmNqcF9wcmQiLCJraWQiOiI2OGI4OWE0Mi02ZjAwLTQzYWUtYjRjNC1hZmRmMGUzZWFlNzQiLCJ0eXAiOiJqd3QiLCJjbHYiOiJKMi4zLjQiLCJhbGciOiJFUzI1NiJ9.eyJhdXQiOiJHVUlEIiwic2NwIjoic2ZjYy5zaG9wcGVyLW15YWNjb3VudC5iYXNrZXRzIHNmY2Muc2hvcHBlci1teWFjY291bnQuYWRkcmVzc2VzIHNmY2Muc2hvcHBlci1wcm9kdWN0cyBzZmNjLnNob3BwZXItbXlhY2NvdW50LnJ3IHNmY2Muc2hvcHBlci1teWFjY291bnQucGF5bWVudGluc3RydW1lbnRzIHNmY2Muc2hvcHBlci1jdXN0b21lcnMubG9naW4gc2ZjYy5zaG9wcGVyLWNvbnRleHQgc2ZjYy5zaG9wcGVyLWNvbnRleHQucncgc2ZjYy5zaG9wcGVyLW15YWNjb3VudC5vcmRlcnMgc2ZjYy5zaG9wcGVyLWN1c3RvbWVycy5yZWdpc3RlciBzZmNjLnNob3BwZXItYmFza2V0cy1vcmRlcnMgc2ZjYy5zaG9wcGVyLW15YWNjb3VudC5hZGRyZXNzZXMucncgc2ZjYy5zaG9wcGVyLW15YWNjb3VudC5wcm9kdWN0bGlzdHMucncgc2ZjYy5zaG9wcGVyLXByb2R1Y3RsaXN0cyBzZmNjLnNob3BwZXItcHJvbW90aW9ucyBzZmNjLnNob3BwZXItYmFza2V0cy1vcmRlcnMucncgc2ZjYy5zaG9wcGVyLW15YWNjb3VudC5wYXltZW50aW5zdHJ1bWVudHMucncgc2ZjYy5zaG9wcGVyLWdpZnQtY2VydGlmaWNhdGVzIHNmY2Muc2hvcHBlci1wcm9kdWN0LXNlYXJjaCBzZmNjLnNob3BwZXItbXlhY2NvdW50LnByb2R1Y3RsaXN0cyBzZmNjLnNob3BwZXItY2F0ZWdvcmllcyBzZmNjLnNob3BwZXItbXlhY2NvdW50Iiwic3ViIjoiY2Mtc2xhczo6YmNqcF9wcmQ6OnNjaWQ6MWM4YzhhM2UtNjU2ZS00MWIxLThiNmYtZmIwNmM0NTFmMDE5Ojp1c2lkOjU3Yjk3ZDc0LTIzZWEtNGIxZi05YzZkLTE4NTVlODI1Y2Q5NiIsImN0eCI6InNsYXMiLCJpc3MiOiJzbGFzL3Byb2QvYmNqcF9wcmQiLCJpc3MiOjEsImRudCI6IjAiLCJhdWQiOiJjb21tZXJjZWNsb3VkL3Byb2QvYmNqcF9wcmQiLCJuYmYiOjE3NTYwODg4ODUsInN0eSI6IlVzZXIiLCJpc2IiOiJ1aWRvOnNsYXM6OnVwbjpHdWVzdDo6dWlkbjpHdWVzdCBVc2VyOjpnY2lkOmFibHJCR21yQklsWG9Sa0hsSndxWVl3SGRLOjpjaGlkOk5BIiwiZXhwIjoxNzU2MDkwNzE1LCJpYXQiOjE3NTYwODg5MTUsImp0aSI6IkMyQy0xODQ0NjA0NzcwMDc0MDYzNDc3MzQ3NjM0MTY2MzA0NTcxMTcifQ.oXAFWFX2Thwrc0mJ0tuYq9E5sDtJHNojKeKYHgv8-Z5zVGkCePB03QjyFw-lE_6EiM4ZW7tE6fFOqOaXYcqqiA",
            "customer-group": "a078f6706670a82b26dee50e6d7d1dacb6d532351e60c225876bec5eb416cf4f",
            "customer-id": "ablrBGmrBIlXoRkHlJwqYYwHdK",
            "refresh-token": "YSnG2ZM7TIQoavZQYts9b5zwREzFLVffDdSOmrkhvmM",
            "bloomreach-id": "uid=2119450463975:v=12.0:ts=1756085787277:hc=4"
        }
        
        # GraphQLæŸ¥è¯¢è¯­å¥ï¼ˆç®€åŒ–ç‰ˆï¼‰
        self.pdp_query = """
        query PDP($id: ID!) {
          product(id: $id) {
            name
            id
            header
            subHeader
            brand
            description
            primaryCategoryId
            productDivision
            disableRatings
            disableReviews
            amountOfReviews
            averageRating
            sizeChartId
            orderable
            colors {
              name
              value
            }
            image {
              href
              verticalImageHref
              alt
            }
            variations {
              id
              masterId
              variantId
              name
              price
              colorValue
              colorName
              ean
              preview
              images {
                alt
                href
                verticalImageHref
              }
              isFinalSale
              validUntil
              isAppExclusive
              badges {
                id
                label
              }
              salePrice
              productPrice {
                price
                salePrice
                promotionPrice
                tax
                taxRate
                bestPrice
              }
              styleNumber
              materialComposition
              orderable
              manufacturerInfo {
                countryOfOrigin {
                  content
                }
              }
            }
          }
        }
        """
        
        # æ–°å¢ï¼šLazyPDPæŸ¥è¯¢è¯­å¥ï¼ˆç”¨äºè·å–è¯¦ç»†å°ºç ä¿¡æ¯ï¼‰
        self.lazy_pdp_query = """
        query LazyPDP($id: ID!) {
          product(id: $id) {
            id
            ...sizes
            variations {
              ...pdpMandatoryExtraVariantFields
              description
              productStory {
                longDescription
                materialComposition
                careInstructions
                manufacturerInfo {
                  manufacturerAddress {
                    label
                    content
                    __typename
                  }
                  countryOfOrigin {
                    label
                    content
                    __typename
                  }
                  __typename
                }
                productKeywords
                __typename
              }
              __typename
            }
            __typename
          }
        }
        fragment sizes on Product {
          productMeasurements {
            metric
            imperial
            __typename
          }
          __typename
        }
        fragment pdpMandatoryExtraVariantFields on Variant {
          id
          sizeGroups {
            label
            description
            sizes {
              id
              label
              value
              productId
              orderable
              maxOrderableQuantity
              __typename
            }
            __typename
          }
          __typename
        }
        """
        
        print("âœ… æ–°çš„PUMA GraphQL APIå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
    
    def get_fresh_token(self):
        """è·å–æ–°çš„è®¤è¯token"""
        try:
            print(f"ğŸ”„ å°è¯•è·å–æ–°çš„è®¤è¯token...")
            
            # åˆ›å»ºä¸€ä¸ªæ–°çš„sessionæ¥é¿å…cookieå¹²æ‰°
            fresh_session = requests.Session()
            
            # è®¾ç½®çœŸå®çš„æµè§ˆå™¨å¤´éƒ¨
            browser_headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36",
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8",
                "Accept-Language": "en-US,en;q=0.9",
                "Accept-Encoding": "gzip, deflate, br",
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Upgrade-Insecure-Requests": "1",
                "Sec-Fetch-Dest": "document",
                "Sec-Fetch-Mode": "navigate",
                "Sec-Fetch-Site": "none",
                "Sec-Fetch-User": "?1"
            }
            
            # 1. é¦–å…ˆè®¿é—®é¦–é¡µå»ºç«‹session
            print(f"ğŸ“ Step 1: è®¿é—®PUMAé¦–é¡µå»ºç«‹ä¼šè¯...")
            homepage_response = fresh_session.get(
                "https://us.puma.com/us/en",
                headers=browser_headers,
                timeout=30
            )
            
            print(f"ğŸ“Š é¦–é¡µå“åº”çŠ¶æ€ç : {homepage_response.status_code}")
            
            if homepage_response.status_code != 200:
                print(f"âŒ æ— æ³•è®¿é—®é¦–é¡µ: {homepage_response.status_code}")
                return False
            
            # 2. è®¿é—®å…·ä½“å•†å“é¡µé¢
            print(f"ğŸ“ Step 2: è®¿é—®å•†å“é¡µé¢...")
            product_url = "https://us.puma.com/us/en/pd/suede-xl-leopard-jr-youth/404299"
            product_response = fresh_session.get(
                product_url,
                headers=browser_headers,
                timeout=30
            )
            
            print(f"ğŸ“Š å•†å“é¡µé¢å“åº”çŠ¶æ€ç : {product_response.status_code}")
            
            if product_response.status_code != 200:
                print(f"âŒ æ— æ³•è®¿é—®å•†å“é¡µé¢: {product_response.status_code}")
                return False
            
            # 3. åˆ†æé¡µé¢å†…å®¹å¯»æ‰¾è®¤è¯ä¿¡æ¯
            print(f"ğŸ“ Step 3: åˆ†æé¡µé¢å†…å®¹å¯»æ‰¾è®¤è¯ä¿¡æ¯...")
            content = product_response.text
            
            # æŸ¥æ‰¾JWT tokençš„å„ç§å¯èƒ½ä½ç½®
            token_patterns = [
                # æ ‡å‡†JWTæ ¼å¼
                r'["\']authorization["\']\s*:\s*["\']Bearer\s+([A-Za-z0-9\-_]+\.[A-Za-z0-9\-_]+\.[A-Za-z0-9\-_]+)["\']',
                r'["\']token["\']\s*:\s*["\']([A-Za-z0-9\-_]+\.[A-Za-z0-9\-_]+\.[A-Za-z0-9\-_]+)["\']',
                r'Bearer\s+([A-Za-z0-9\-_]+\.[A-Za-z0-9\-_]+\.[A-Za-z0-9\-_]+)',
                # ç›´æ¥çš„JWT token
                r'["\']([A-Za-z0-9\-_]{20,}\.[A-Za-z0-9\-_]{20,}\.[A-Za-z0-9\-_]{20,})["\']',
                # JavaScriptå˜é‡ä¸­çš„token
                r'token\s*[=:]\s*["\']([A-Za-z0-9\-_]+\.[A-Za-z0-9\-_]+\.[A-Za-z0-9\-_]+)["\']',
                r'auth(?:orization)?\s*[=:]\s*["\']Bearer\s+([A-Za-z0-9\-_]+\.[A-Za-z0-9\-_]+\.[A-Za-z0-9\-_]+)["\']',
                # windowå¯¹è±¡ä¸­çš„token
                r'window\.[^=]*=\s*["\']([A-Za-z0-9\-_]+\.[A-Za-z0-9\-_]+\.[A-Za-z0-9\-_]+)["\']',
                # é…ç½®å¯¹è±¡ä¸­çš„token
                r'config[^}]*["\']token["\'][^"\']++["\']([A-Za-z0-9\-_]+\.[A-Za-z0-9\-_]+\.[A-Za-z0-9\-_]+)["\']'
            ]
            
            # æŸ¥æ‰¾å…¶ä»–è®¤è¯å¤´ä¿¡æ¯
            auth_patterns = {
                'customer-group': [r'["\']customer[_-]?group["\']\\s*:\\s*["\']([^"\']+)["\']', r'customerGroup["\']\\s*:\\s*["\']([^"\']+)["\']'],
                'customer-id': [r'["\']customer[_-]?id["\']\\s*:\\s*["\']([^"\']+)["\']', r'customerId["\']\\s*:\\s*["\']([^"\']+)["\']'],
                'refresh-token': [r'["\']refresh[_-]?token["\']\\s*:\\s*["\']([^"\']+)["\']', r'refreshToken["\']\\s*:\\s*["\']([^"\']+)["\']'],
                'bloomreach-id': [r'["\']bloomreach[_-]?id["\']\\s*:\\s*["\']([^"\']+)["\']', r'bloomreachId["\']\\s*:\\s*["\']([^"\']+)["\']']
            }
            
            found_tokens = []
            for pattern in token_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                for match in matches:
                    # éªŒè¯JWTæ ¼å¼ï¼ˆä¸‰éƒ¨åˆ†ç”¨.åˆ†éš”ï¼‰å’Œé•¿åº¦
                    if len(match.split('.')) == 3 and len(match) > 50:
                        # æ£€æŸ¥æ˜¯å¦ä¸ºæ–°tokenï¼ˆä¸å½“å‰çš„ä¸åŒï¼‰
                        current_token = self.auth_headers.get("authorization", "").replace("Bearer ", "")
                        if match != current_token:
                            found_tokens.append(match)
                            print(f"âœ… æ‰¾åˆ°æ–°çš„JWT token: {match[:30]}...{match[-10:]}")
            
            if found_tokens:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„æœ‰æ•ˆtoken
                new_token = found_tokens[0]
                print(f"âœ… åœ¨é¡µé¢ä¸­æ‰¾åˆ°JWT token: {new_token[:50]}...")
                self.auth_headers["authorization"] = f"Bearer {new_token}"
                
                # å°è¯•æŸ¥æ‰¾å…¶ä»–è®¤è¯ä¿¡æ¯
                for header_name, patterns in auth_patterns.items():
                    for pattern in patterns:
                        matches = re.findall(pattern, content, re.IGNORECASE)
                        if matches:
                            self.auth_headers[header_name] = matches[0]
                            print(f"âœ… æ‰¾åˆ° {header_name}: {matches[0][:20]}...")
                            break
                
                print(f"âœ… æˆåŠŸæ›´æ–°è®¤è¯ä¿¡æ¯")
                return True
            
            # 4. å¦‚æœé¡µé¢ä¸­æ²¡æ‰¾åˆ°ï¼Œå°è¯•ä½¿ç”¨RefreshLogon APIåˆ·æ–°token
            print(f"ğŸ“ Step 4: å°è¯•ä½¿ç”¨RefreshLogon APIåˆ·æ–°token...")
            refresh_success = self._try_refresh_logon_api(fresh_session)
            if refresh_success:
                return True
            
            # 5. å¦‚æœRefreshLogonå¤±è´¥ï¼Œå°è¯•æ¨¡æ‹ŸGraphQLè¯·æ±‚è§¦å‘tokenç”Ÿæˆ
            print(f"ğŸ“ Step 5: å°è¯•é€šè¿‡GraphQL APIè§¦å‘tokenç”Ÿæˆ...")
            graphql_headers = {
                **browser_headers,
                "Content-Type": "application/json",
                "Origin": "https://us.puma.com",
                "Referer": product_url,
                "x-graphql-client-name": "nitro-fe",
                "x-graphql-client-version": "961757de4b96db7c1c36770d26de3e4fb6f16f24"
            }
            
            # ç®€å•çš„æŸ¥è¯¢è¯·æ±‚
            simple_query = {
                "operationName": "GetSiteConfig",
                "query": "query GetSiteConfig { __typename }",
                "variables": {}
            }
            
            api_response = fresh_session.post(
                "https://us.puma.com/api/graphql",
                headers=graphql_headers,
                json=simple_query,
                timeout=30
            )
            
            print(f"ğŸ“Š GraphQL APIå“åº”çŠ¶æ€ç : {api_response.status_code}")
            
            # æ£€æŸ¥å“åº”å¤´æ˜¯å¦åŒ…å«æ–°çš„è®¤è¯ä¿¡æ¯
            response_headers = api_response.headers
            if 'set-cookie' in response_headers:
                print(f"ğŸ“Š APIå“åº”åŒ…å«Cookieä¿¡æ¯")
            
            # å°è¯•ä»å“åº”ä¸­æå–tokenï¼ˆæŸäº›APIä¼šåœ¨å“åº”ä¸­è¿”å›tokenï¼‰
            if api_response.status_code == 200:
                try:
                    response_data = api_response.json()
                    print(f"ğŸ“Š APIå“åº”åŒ…å«æ•°æ®")
                    # è¿™é‡Œå¯ä»¥æ ¹æ®APIçš„å…·ä½“å“åº”æ ¼å¼æ¥æå–token
                except:
                    pass
            
            print(f"âš ï¸ æ— æ³•è‡ªåŠ¨è·å–æ–°çš„è®¤è¯token")
            
            # 6. Fallbackç­–ç•¥ï¼šå°è¯•ä»é¡¹ç›®ä¸­å…¶ä»–APIå®¢æˆ·ç«¯è·å–token
            print(f"ğŸ“ Step 6: Fallback - å°è¯•ä»é¡¹ç›®ä¸­å…¶ä»–APIå®¢æˆ·ç«¯è·å–token...")
            try:
                # å°è¯•å¯¼å…¥å¹¶è·å–å…¶ä»–APIå®¢æˆ·ç«¯çš„token
                import sys
                import os
                project_root = os.path.dirname(os.path.dirname(__file__))
                if project_root not in sys.path:
                    sys.path.insert(0, project_root)
                
                # å°è¯•ä»complete_graphql_apiè·å–token
                try:
                    from complete_graphql_api import CompleteGraphQLAPI
                    backup_api = CompleteGraphQLAPI()
                    if hasattr(backup_api, 'headers') and 'authorization' in backup_api.headers:
                        backup_token = backup_api.headers['authorization']
                        if backup_token and backup_token != self.auth_headers.get('authorization'):
                            print(f"âœ… ä»CompleteGraphQLAPIè·å–åˆ°backup token")
                            self.auth_headers['authorization'] = backup_token
                            return True
                except ImportError:
                    pass
                
                # å°è¯•ä»working_complete_graphql_apiè·å–token
                try:
                    from working_complete_graphql_api import WorkingCompleteGraphQLAPI
                    backup_api = WorkingCompleteGraphQLAPI()
                    if hasattr(backup_api, 'auth_headers') and 'authorization' in backup_api.auth_headers:
                        backup_token = backup_api.auth_headers['authorization']
                        if backup_token and backup_token != self.auth_headers.get('authorization'):
                            print(f"âœ… ä»WorkingCompleteGraphQLAPIè·å–åˆ°backup token")
                            # å¤åˆ¶æ‰€æœ‰è®¤è¯å¤´
                            for key, value in backup_api.auth_headers.items():
                                self.auth_headers[key] = value
                            return True
                except ImportError:
                    pass
                    
            except Exception as e:
                print(f"âŒ Fallbackç­–ç•¥å¤±è´¥: {e}")
            
            return False
            
        except Exception as e:
            print(f"âŒ è·å–æ–°tokenæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _try_refresh_logon_api(self, session):
        """å°è¯•ä½¿ç”¨RefreshLogon APIåˆ·æ–°token"""
        try:
            current_refresh_token = self.auth_headers.get("refresh-token")
            if not current_refresh_token:
                print(f"âš ï¸ æ²¡æœ‰å¯ç”¨çš„refresh-token")
                return False
            
            print(f"âœ… ä½¿ç”¨ç°æœ‰refresh-token: {current_refresh_token[:20]}...")
            
            # RefreshLogon GraphQLæŸ¥è¯¢
            refresh_query = {
                "operationName": "RefreshLogon",
                "query": """mutation RefreshLogon($input: RefreshLogonInput!) {
  refreshLogon(input: $input) {
    ...tokenPayload
  }
}
fragment tokenPayload on TokenPayload {
  __typename
  accessToken
  refreshToken
  customerId
  uniqueShopperId
  customerContext {
    __typename
    hashKey
    customerGroups
  }
  user {
    customerNo
    email
  }
}""",
                "variables": {
                    "input": {
                        "refreshToken": current_refresh_token
                    }
                }
            }
            
            # å‡†å¤‡è¯·æ±‚å¤´
            refresh_headers = {
                "accept": "application/graphql-response+json, application/graphql+json, application/json",
                "accept-language": "zh-CN,zh;q=0.9",
                "content-type": "application/json",
                "locale": "en-US",
                "origin": "https://us.puma.com",
                "priority": "u=1, i",
                "puma-request-source": "web",
                "referer": "https://us.puma.com/us/en/pd/suede-xl-super-puma-jr-youth/403380?swatch=01",
                "sec-ch-ua": '"Not;A=Brand";v="99", "Google Chrome";v="139", "Chromium";v="139"',
                "sec-ch-ua-mobile": "?0",
                "sec-ch-ua-platform": '"Windows"',
                "sec-fetch-dest": "empty",
                "sec-fetch-mode": "cors",
                "sec-fetch-site": "same-origin",
                "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36",
                "x-graphql-client-name": "nitro-fe",
                "x-graphql-client-version": "961757de4b96db7c1c36770d26de3e4fb6f16f24",
                "x-operation-name": "RefreshLogon"
            }
            
            # æ·»åŠ å½“å‰çš„è®¤è¯ä¿¡æ¯
            if self.auth_headers.get("authorization"):
                refresh_headers["authorization"] = self.auth_headers["authorization"]
            if self.auth_headers.get("customer-group"):
                refresh_headers["customer-group"] = self.auth_headers["customer-group"]
            if self.auth_headers.get("customer-id"):
                refresh_headers["customer-id"] = self.auth_headers["customer-id"]
            if self.auth_headers.get("refresh-token"):
                refresh_headers["refresh-token"] = self.auth_headers["refresh-token"]
            if self.auth_headers.get("bloomreach-id"):
                refresh_headers["bloomreach-id"] = self.auth_headers["bloomreach-id"]
            
            print(f"ğŸ“ å‘é€RefreshLogonè¯·æ±‚...")
            response = session.post(
                "https://us.puma.com/api/graphql",
                headers=refresh_headers,
                json=refresh_query,
                timeout=30
            )
            
            print(f"ğŸ“Š RefreshLogonå“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                try:
                    data = response.json()
                    if 'data' in data and 'refreshLogon' in data['data'] and data['data']['refreshLogon']:
                        token_payload = data['data']['refreshLogon']
                        
                        # è·å–æ–°çš„è®¤è¯ä¿¡æ¯
                        new_access_token = token_payload.get('accessToken')
                        new_refresh_token = token_payload.get('refreshToken')
                        new_customer_id = token_payload.get('customerId')
                        
                        if new_access_token:
                            print(f"âœ… RefreshLogonæˆåŠŸï¼è·å–åˆ°æ–°çš„accessToken")
                            
                            # æ›´æ–°è®¤è¯ä¿¡æ¯
                            self.auth_headers["authorization"] = f"Bearer {new_access_token}"
                            
                            if new_refresh_token:
                                self.auth_headers["refresh-token"] = new_refresh_token
                                print(f"âœ… æ›´æ–°refresh-token: {new_refresh_token[:20]}...")
                            
                            if new_customer_id:
                                self.auth_headers["customer-id"] = new_customer_id
                                print(f"âœ… æ›´æ–°customer-id: {new_customer_id}")
                            
                            # æ›´æ–°customerContextä¸­çš„hashKeyä½œä¸ºcustomer-group
                            customer_context = token_payload.get('customerContext', {})
                            if customer_context and customer_context.get('hashKey'):
                                self.auth_headers["customer-group"] = customer_context['hashKey']
                                print(f"âœ… æ›´æ–°customer-group: {customer_context['hashKey'][:20]}...")
                            
                            print(f"âœ… RefreshLogon APIåˆ·æ–°tokenæˆåŠŸï¼")
                            return True
                        else:
                            print(f"âŒ RefreshLogonå“åº”ä¸­æ²¡æœ‰accessToken")
                            return False
                    elif 'errors' in data:
                        print(f"âŒ RefreshLogoné”™è¯¯: {data['errors']}")
                        return False
                    else:
                        print(f"âŒ RefreshLogonå“åº”æ ¼å¼ä¸æ­£ç¡®")
                        return False
                        
                except json.JSONDecodeError as e:
                    print(f"âŒ RefreshLogonå“åº”JSONè§£æå¤±è´¥: {e}")
                    return False
            else:
                print(f"âŒ RefreshLogonè¯·æ±‚å¤±è´¥: {response.status_code}")
                if response.text:
                    print(f"   å“åº”å†…å®¹: {response.text[:200]}...")
                return False
                
        except Exception as e:
            print(f"âŒ RefreshLogon APIè°ƒç”¨å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def extract_product_id(self, url: str) -> Optional[str]:
        """ä»PUMAå•†å“URLä¸­æå–å•†å“ID"""
        try:
            # å¤šç§URLæ ¼å¼çš„åŒ¹é…æ¨¡å¼
            patterns = [
                r'/pd/[^/]+/(\d+)',  # æ ‡å‡†æ ¼å¼: /pd/product-name/123456
                r'product[_-]?id[=:](\d+)',  # æŸ¥è¯¢å‚æ•°æ ¼å¼
                r'/(\d{6})(?:[/?]|$)',  # 6ä½æ•°å­—ID
                r'/(\d{5,7})(?:[/?]|$)',  # 5-7ä½æ•°å­—ID
            ]
            
            for pattern in patterns:
                match = re.search(pattern, url, re.IGNORECASE)
                if match:
                    product_id = match.group(1)
                    print(f"âœ… ä»URLæå–åˆ°å•†å“ID: {product_id}")
                    return product_id
            
            print(f"âŒ æ— æ³•ä»URLæå–å•†å“ID: {url}")
            return None
            
        except Exception as e:
            print(f"âŒ æå–å•†å“IDæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None
    
    def scrape_product(self, url: str) -> Optional[ProductInfo]:
        """ä¸»è¦æ¥å£ï¼šçˆ¬å–å•†å“ä¿¡æ¯"""
        try:
            print(f"ğŸ” å¼€å§‹çˆ¬å–å•†å“: {url}")
            
            # æå–å•†å“ID
            product_id = self.extract_product_id(url)
            if not product_id:
                return None
            
            # è·å–åŸºæœ¬å•†å“ä¿¡æ¯
            product_info = self.get_product_info(product_id)
            if not product_info:
                return None
            
            # è·å–è¯¦ç»†å°ºç ä¿¡æ¯
            print(f"ğŸ” è·å–è¯¦ç»†å°ºç ä¿¡æ¯...")
            detailed_size_data = self.get_detailed_size_info(product_id)
            if detailed_size_data:
                # åˆå¹¶è¯¦ç»†å°ºç ä¿¡æ¯åˆ°åŸºæœ¬å•†å“ä¿¡æ¯ä¸­
                self._merge_detailed_size_info(product_info, detailed_size_data)
                print(f"âœ… æˆåŠŸåˆå¹¶è¯¦ç»†å°ºç ä¿¡æ¯")
            else:
                print(f"âš ï¸ æ— æ³•è·å–è¯¦ç»†å°ºç ä¿¡æ¯ï¼Œä½¿ç”¨åŸºæœ¬ä¿¡æ¯")
            
            # è·å–å¯¼èˆªä¿¡æ¯
            print(f"ğŸ” è·å–å¯¼èˆªä¿¡æ¯...")
            breadcrumb_items, navigation_path = self._extract_breadcrumb_from_html(url)
            if breadcrumb_items:
                product_info.breadcrumb = breadcrumb_items
                product_info.navigation_path = navigation_path
                print(f"âœ… æˆåŠŸè·å–å¯¼èˆªä¿¡æ¯: {navigation_path}")
            else:
                print(f"âš ï¸ æ— æ³•è·å–å¯¼èˆªä¿¡æ¯")
            
            product_info.url = url
            product_info.scraped_at = datetime.now().isoformat()
            print(f"âœ… æˆåŠŸçˆ¬å–å•†å“: {product_info.name}")
            return product_info
            
        except Exception as e:
            print(f"âŒ çˆ¬å–å•†å“æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def get_detailed_size_info(self, product_id: str) -> Optional[Dict]:
        """é€šè¿‡LazyPDP APIè·å–è¯¦ç»†çš„å°ºç ä¿¡æ¯å’Œå•†å“æµ‹é‡æ•°æ®"""
        try:
            print(f"ğŸ” æ­£åœ¨è·å–è¯¦ç»†å°ºç ä¿¡æ¯ï¼ŒID: {product_id}")
            
            # å‡†å¤‡è¯·æ±‚å¤´
            request_headers = {**self.headers, **self.auth_headers}
            request_headers["referer"] = f"https://us.puma.com/us/en/pd/product/{product_id}"
            request_headers["x-operation-name"] = "LazyPDP"
            
            # å‡†å¤‡GraphQLè¯·æ±‚æ•°æ®
            payload = {
                "operationName": "LazyPDP",
                "query": self.lazy_pdp_query,
                "variables": {"id": product_id}
            }
            
            print(f"ğŸ“¡ å‘é€LazyPDPè¯·æ±‚...")
            response = self.session.post(
                self.base_url,
                headers=request_headers,
                json=payload,
                timeout=30
            )
            
            print(f"ğŸ“ˆ LazyPDPå“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                try:
                    data = response.json()
                    print(f"âœ… æˆåŠŸè·å–LazyPDP JSONå“åº”")
                    
                    if 'errors' in data:
                        errors = data['errors']
                        print(f"âŒ LazyPDP GraphQLé”™è¯¯: {errors}")
                        
                        # æ£€æŸ¥æ˜¯å¦æ˜¯è®¤è¯é”™è¯¯
                        for error in errors:
                            if error.get('extensions', {}).get('code') == 'UNAUTHENTICATED':
                                print(f"âš ï¸ è®¤è¯å¤±è´¥ï¼Œå°è¯•è·å–æ–°token...")
                                if self.get_fresh_token():
                                    print(f"ğŸ”„ è·å–æ–°tokenæˆåŠŸï¼Œé‡è¯•è¯·æ±‚...")
                                    # é‡æ–°å‡†å¤‡è¯·æ±‚å¤´
                                    request_headers = {**self.headers, **self.auth_headers}
                                    request_headers["referer"] = f"https://us.puma.com/us/en/pd/product/{product_id}"
                                    request_headers["x-operation-name"] = "LazyPDP"
                                    
                                    # é‡è¯•è¯·æ±‚
                                    retry_response = self.session.post(
                                        self.base_url,
                                        headers=request_headers,
                                        json=payload,
                                        timeout=30
                                    )
                                    
                                    if retry_response.status_code == 200:
                                        retry_data = retry_response.json()
                                        if 'data' in retry_data and 'product' in retry_data['data'] and retry_data['data']['product']:
                                            product_data = retry_data['data']['product']
                                            print(f"âœ… é‡è¯•æˆåŠŸï¼è·å–åˆ°è¯¦ç»†å°ºç æ•°æ®")
                                            return product_data
                                        elif 'errors' in retry_data:
                                            print(f"âŒ é‡è¯•åä»æœ‰é”™è¯¯: {retry_data['errors']}")
                                    else:
                                        print(f"âŒ é‡è¯•è¯·æ±‚å¤±è´¥: {retry_response.status_code}")
                                else:
                                    print(f"âŒ æ— æ³•è·å–æ–°token")
                                break
                        return None
                    
                    if 'data' in data and 'product' in data['data'] and data['data']['product']:
                        product_data = data['data']['product']
                        print(f"âœ… æˆåŠŸè·å–è¯¦ç»†å°ºç æ•°æ®")
                        return product_data
                    else:
                        print(f"âŒ å“åº”æ•°æ®ä¸­æ²¡æœ‰å•†å“ä¿¡æ¯")
                        return None
                        
                except json.JSONDecodeError as e:
                    print(f"âŒ LazyPDP JSONè§£æé”™è¯¯: {e}")
                    print(f"å“åº”å†…å®¹: {response.text[:500]}...")
                    return None
            else:
                print(f"âŒ LazyPDP HTTPè¯·æ±‚å¤±è´¥: {response.status_code}")
                print(f"å“åº”å†…å®¹: {response.text[:500]}...")
                return None
                
        except Exception as e:
            print(f"âŒ è·å–è¯¦ç»†å°ºç ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def get_product_info(self, product_id: str) -> Optional[ProductInfo]:
        try:
            print(f"ğŸ” æ­£åœ¨è·å–å•†å“ä¿¡æ¯ï¼ŒID: {product_id}")
            
            # å‡†å¤‡è¯·æ±‚å¤´
            request_headers = {**self.headers, **self.auth_headers}
            request_headers["referer"] = f"https://us.puma.com/us/en/pd/product/{product_id}"
            
            # å‡†å¤‡GraphQLè¯·æ±‚æ•°æ®
            payload = {
                "operationName": "PDP",
                "query": self.pdp_query,
                "variables": {"id": product_id}
            }
            
            print(f"ğŸ“¡ å‘é€GraphQLè¯·æ±‚...")
            response = self.session.post(
                self.base_url,
                headers=request_headers,
                json=payload,
                timeout=30
            )
            
            print(f"ğŸ“Š å“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                try:
                    data = response.json()
                    print(f"âœ… æˆåŠŸè·å–JSONå“åº”")
                    
                    if 'errors' in data:
                        errors = data['errors']
                        print(f"âŒ GraphQLé”™è¯¯: {errors}")
                        
                        # æ£€æŸ¥æ˜¯å¦æ˜¯è®¤è¯é”™è¯¯
                        for error in errors:
                            if error.get('extensions', {}).get('code') == 'UNAUTHENTICATED':
                                print("âš ï¸ è®¤è¯å¤±è´¥ï¼Œå°è¯•è·å–æ–°token...")
                                if self.get_fresh_token():
                                    print("ğŸ”„ è·å–æ–°tokenæˆåŠŸï¼Œé‡è¯•è¯·æ±‚...")
                                    # é‡æ–°å‡†å¤‡è¯·æ±‚å¤´
                                    request_headers = {**self.headers, **self.auth_headers}
                                    request_headers["referer"] = f"https://us.puma.com/us/en/pd/product/{product_id}"
                                    
                                    # é‡è¯•è¯·æ±‚
                                    retry_response = self.session.post(
                                        self.base_url,
                                        headers=request_headers,
                                        json=payload,
                                        timeout=30
                                    )
                                    
                                    if retry_response.status_code == 200:
                                        retry_data = retry_response.json()
                                        if 'data' in retry_data and 'product' in retry_data['data'] and retry_data['data']['product']:
                                            product_data = retry_data['data']['product']
                                            print(f"âœ… é‡è¯•æˆåŠŸï¼è·å–åˆ°å•†å“æ•°æ®: {product_data.get('name', 'Unknown')}")
                                            return self._parse_product_data(product_data)
                                        elif 'errors' in retry_data:
                                            print(f"âŒ é‡è¯•åä»æœ‰é”™è¯¯: {retry_data['errors']}")
                                    else:
                                        print(f"âŒ é‡è¯•è¯·æ±‚å¤±è´¥: {retry_response.status_code}")
                                else:
                                    print("âŒ æ— æ³•è·å–æ–°token")
                                break
                        return None
                    
                    if 'data' in data and 'product' in data['data'] and data['data']['product']:
                        product_data = data['data']['product']
                        print(f"âœ… æˆåŠŸè·å–å•†å“æ•°æ®: {product_data.get('name', 'Unknown')}")
                        return self._parse_product_data(product_data)
                    else:
                        print(f"âŒ å“åº”æ•°æ®ä¸­æ²¡æœ‰å•†å“ä¿¡æ¯")
                        return None
                        
                except json.JSONDecodeError as e:
                    print(f"âŒ JSONè§£æé”™è¯¯: {e}")
                    print(f"å“åº”å†…å®¹: {response.text[:500]}...")
                    return None
            else:
                print(f"âŒ HTTPè¯·æ±‚å¤±è´¥: {response.status_code}")
                print(f"å“åº”å†…å®¹: {response.text[:500]}...")
                return None
                
        except Exception as e:
            print(f"âŒ è·å–å•†å“ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _parse_product_data(self, product_data: Dict) -> ProductInfo:
        """è§£æGraphQLå“åº”æ•°æ®ä¸ºProductInfoå¯¹è±¡"""
        try:
            print(f"ğŸ“‹ å¼€å§‹è§£æå•†å“æ•°æ®...")
            
            product_info = ProductInfo()
            
            # åŸºæœ¬ä¿¡æ¯
            product_info.name = product_data.get('name', '')
            product_info.header = product_data.get('header', '')
            product_info.sub_header = product_data.get('subHeader', '')
            product_info.brand = product_data.get('brand', '')
            product_info.product_id = str(product_data.get('id', ''))
            product_info.description = product_data.get('description', '')
            product_info.orderable = product_data.get('orderable', True)
            product_info.primary_category_id = product_data.get('primaryCategoryId', '')
            product_info.product_division = product_data.get('productDivision', '')
            
            # è¯„ä»·ä¿¡æ¯
            product_info.rating = product_data.get('averageRating')
            product_info.reviews_count = product_data.get('amountOfReviews')
            product_info.disable_ratings = product_data.get('disableRatings')
            product_info.disable_reviews = product_data.get('disableReviews')
            product_info.size_chart_id = product_data.get('sizeChartId', '')
            
            # å¤„ç†ä¸»å›¾ç‰‡
            main_image = product_data.get('image', {})
            if main_image and main_image.get('href'):
                product_info.preview_image = main_image['href']
                product_info.images.append(main_image['href'])
                if main_image.get('verticalImageHref'):
                    product_info.vertical_images.append(main_image['verticalImageHref'])
            
            # å¤„ç†é¢œè‰²ä¿¡æ¯
            colors = product_data.get('colors', [])
            if colors:
                first_color = colors[0]
                product_info.color = first_color.get('name', '')
                product_info.color_name = first_color.get('name', '')
                product_info.color_value = first_color.get('value', '')
                product_info.color_code = first_color.get('value', '')
            
            # å¤„ç†å˜ä½“ä¿¡æ¯
            variations = product_data.get('variations', [])
            if variations:
                first_variant = variations[0]
                
                # æ›´æ–°åŸºæœ¬ä¿¡æ¯
                product_info.variant_id = first_variant.get('variantId', '')
                product_info.sku = first_variant.get('id', '')
                product_info.style_number = first_variant.get('styleNumber', '')
                product_info.ean = first_variant.get('ean', '')
                
                # ä»·æ ¼ä¿¡æ¯
                product_info.price = float(first_variant.get('price', 0))
                product_info.sale_price = float(first_variant.get('salePrice', 0))
                
                # å¤„ç†äº§å“ä»·æ ¼å¯¹è±¡
                product_price = first_variant.get('productPrice', {})
                if product_price:
                    product_info.original_price = float(product_price.get('price', 0))
                    product_info.sale_price = float(product_price.get('salePrice', 0))
                    product_info.promotion_price = product_price.get('promotionPrice')
                    product_info.best_price = product_price.get('bestPrice')
                    product_info.tax = float(product_price.get('tax', 0))
                    product_info.tax_rate = float(product_price.get('taxRate', 0))
                
                # è®¡ç®—æŠ˜æ‰£
                if product_info.original_price > 0 and product_info.sale_price > 0:
                    product_info.discount = ((product_info.original_price - product_info.sale_price) / product_info.original_price) * 100
                
                # é¢œè‰²ä¿¡æ¯ï¼ˆä»å˜ä½“è·å–ï¼‰
                if not product_info.color:
                    product_info.color_name = first_variant.get('colorName', '')
                    product_info.color_value = first_variant.get('colorValue', '')
                    product_info.color = first_variant.get('colorName', '')
                    product_info.color_code = first_variant.get('colorValue', '')
                
                # çŠ¶æ€ä¿¡æ¯
                product_info.orderable = first_variant.get('orderable', True)
                product_info.is_final_sale = first_variant.get('isFinalSale')
                product_info.valid_until = first_variant.get('validUntil', '')
                product_info.is_app_exclusive = first_variant.get('isAppExclusive', False)
                
                # å¤„ç†å¾½ç« 
                badges = first_variant.get('badges', [])
                if badges:
                    product_info.badges = [badge.get('label', '') for badge in badges if badge.get('label')]
                
                # å¤„ç†ææ–™ç»„æˆ
                material_composition = first_variant.get('materialComposition', [])
                if material_composition:
                    product_info.material_composition = material_composition
                    product_info.materials = material_composition
                
                # å¤„ç†åˆ¶é€ ä¿¡æ¯
                manufacturer_info = first_variant.get('manufacturerInfo', {})
                if manufacturer_info:
                    product_info.manufacturer_info = manufacturer_info
                    country_info = manufacturer_info.get('countryOfOrigin', {})
                    if country_info and country_info.get('content'):
                        content = country_info['content']
                        if isinstance(content, list) and content:
                            product_info.country_of_origin = content[0]
                        elif isinstance(content, str):
                            product_info.country_of_origin = content
                
                # å¤„ç†å›¾ç‰‡ï¼ˆä»å˜ä½“è·å–ï¼‰
                variant_images = first_variant.get('images', [])
                for img in variant_images:
                    if img.get('href') and img['href'] not in product_info.images:
                        product_info.images.append(img['href'])
                    if img.get('verticalImageHref') and img['verticalImageHref'] not in product_info.vertical_images:
                        product_info.vertical_images.append(img['verticalImageHref'])
                
                # é¢„è§ˆå›¾ç‰‡
                if first_variant.get('preview') and not product_info.preview_image:
                    product_info.preview_image = first_variant['preview']
            
            product_info.availability = "æœ‰åº“å­˜"
            product_info.stock_status = "available"
            
            print(f"âœ… å•†å“æ•°æ®è§£æå®Œæˆ: {product_info.name}")
            return product_info
            
        except Exception as e:
            print(f"âŒ è§£æå•†å“æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _merge_detailed_size_info(self, product_info: ProductInfo, detailed_data: Dict) -> None:
        """åˆå¹¶è¯¦ç»†å°ºç ä¿¡æ¯åˆ°ProductInfoå¯¹è±¡ä¸­"""
        try:
            print(f"ğŸ”„ å¼€å§‹åˆå¹¶è¯¦ç»†å°ºç ä¿¡æ¯...")
            
            # å¤„ç†å•†å“æµ‹é‡è¡¨
            product_measurements = detailed_data.get('productMeasurements')
            if product_measurements:
                product_info.product_measurements = product_measurements
                
                # å…¬åˆ¶æµ‹é‡æ•°æ®
                if product_measurements.get('metric'):
                    product_info.metric_measurements = product_measurements['metric']
                    print(f"âœ… è·å–åˆ°å…¬åˆ¶æµ‹é‡æ•°æ®: {len(product_measurements['metric'])} è¡Œ")
                
                # è‹±åˆ¶æµ‹é‡æ•°æ®
                if product_measurements.get('imperial'):
                    product_info.imperial_measurements = product_measurements['imperial']
                    print(f"âœ… è·å–åˆ°è‹±åˆ¶æµ‹é‡æ•°æ®: {len(product_measurements['imperial'])} è¡Œ")
            
            # å¤„ç†å˜ä½“è¯¦ç»†ä¿¡æ¯
            variations = detailed_data.get('variations', [])
            if variations:
                first_variant = variations[0]
                
                # å¤„ç†å°ºç ç»„ä¿¡æ¯
                size_groups = first_variant.get('sizeGroups', [])
                if size_groups:
                    product_info.size_groups = size_groups
                    
                    # æå–æ‰€æœ‰å°ºç ä¿¡æ¯
                    all_sizes = []
                    available_sizes = []
                    unavailable_sizes = []
                    
                    for size_group in size_groups:
                        sizes = size_group.get('sizes', [])
                        for size in sizes:
                            size_label = size.get('label', '')
                            if size_label:
                                all_sizes.append(size_label)
                                if size.get('orderable', False):
                                    available_sizes.append(size_label)
                                else:
                                    unavailable_sizes.append(size_label)
                    
                    # æ›´æ–°å°ºç ä¿¡æ¯
                    if all_sizes:
                        product_info.sizes = all_sizes
                        product_info.available_sizes = available_sizes
                        product_info.unavailable_sizes = unavailable_sizes
                        print(f"âœ… æ›´æ–°å°ºç ä¿¡æ¯: æ€»å…±{len(all_sizes)}ä¸ª, å¯ç”¨{len(available_sizes)}ä¸ª, ä¸å¯ç”¨{len(unavailable_sizes)}ä¸ª")
                
                # å¤„ç†äº§å“æ•…äº‹ä¿¡æ¯
                product_story = first_variant.get('productStory')
                if product_story:
                    # æ›´æ–°æè¿°ä¿¡æ¯
                    if product_story.get('longDescription') and not product_info.description:
                        product_info.description = product_story['longDescription']
                        print(f"âœ… æ›´æ–°å•†å“è¯¦ç»†æè¿°")
                    
                    # æ›´æ–°ææ–™ç»„æˆ
                    material_composition = product_story.get('materialComposition', [])
                    if material_composition:
                        product_info.material_composition = material_composition
                        product_info.materials = material_composition
                        print(f"âœ… æ›´æ–°ææ–™ç»„æˆ: {len(material_composition)} é¡¹")
                    
                    # æ›´æ–°æŠ¤ç†è¯´æ˜
                    care_instructions = product_story.get('careInstructions')
                    if care_instructions:
                        if isinstance(care_instructions, list):
                            product_info.care_instructions = care_instructions
                        elif isinstance(care_instructions, str):
                            product_info.care_instructions = [care_instructions]
                        print(f"âœ… æ›´æ–°æŠ¤ç†è¯´æ˜")
                    
                    # æ›´æ–°åˆ¶é€ å•†ä¿¡æ¯
                    manufacturer_info = product_story.get('manufacturerInfo')
                    if manufacturer_info:
                        if not product_info.manufacturer_info:
                            product_info.manufacturer_info = {}
                        
                        # åˆå¹¶åˆ¶é€ å•†ä¿¡æ¯
                        product_info.manufacturer_info.update(manufacturer_info)
                        
                        # æ›´æ–°åŸäº§åœ°ä¿¡æ¯
                        country_info = manufacturer_info.get('countryOfOrigin', {})
                        if country_info and country_info.get('content'):
                            content = country_info['content']
                            if isinstance(content, list) and content and content[0]:
                                product_info.country_of_origin = content[0]
                            elif isinstance(content, str) and content:
                                product_info.country_of_origin = content
                            print(f"âœ… æ›´æ–°åŸäº§åœ°ä¿¡æ¯: {product_info.country_of_origin}")
                    
                    # æ›´æ–°äº§å“å…³é”®è¯
                    product_keywords = product_story.get('productKeywords', [])
                    if product_keywords:
                        # å°†å…³é”®è¯ä½œä¸ºç‰¹æ€§æ·»åŠ 
                        if not product_info.features:
                            product_info.features = []
                        product_info.features.extend(product_keywords)
                        print(f"âœ… æ›´æ–°äº§å“å…³é”®è¯: {len(product_keywords)} ä¸ª")
                
                # æ›´æ–°å˜ä½“æè¿°
                variant_description = first_variant.get('description')
                if variant_description and len(variant_description) > len(product_info.description):
                    product_info.description = variant_description
                    print(f"âœ… æ›´æ–°ä¸ºæ›´è¯¦ç»†çš„å˜ä½“æè¿°")
            
            print(f"âœ… è¯¦ç»†å°ºç ä¿¡æ¯åˆå¹¶å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ åˆå¹¶è¯¦ç»†å°ºç ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
    
    def _extract_breadcrumb_from_html(self, url: str) -> tuple:
        """ä»é¡µé¢HTMLä¸­æå–é¢åŒ…å±‘å¯¼èˆªä¿¡æ¯"""
        try:
            print(f"ğŸ” å¼€å§‹æå–å¯¼èˆªä¿¡æ¯: {url}")
            
            # è®¾ç½®æµè§ˆå™¨å¤´éƒ¨
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36",
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8",
                "Accept-Language": "en-US,en;q=0.9",
                "Accept-Encoding": "gzip, deflate, br",
                "Cache-Control": "no-cache",
                "Connection": "keep-alive"
            }
            
            # è·å–é¡µé¢HTML
            response = self.session.get(url, headers=headers, timeout=30)
            
            if response.status_code != 200:
                print(f"âŒ æ— æ³•è·å–é¡µé¢: {response.status_code}")
                return [], ""
            
            html_content = response.text
            print(f"âœ… æˆåŠŸè·å–é¡µé¢HTMLï¼Œé•¿åº¦: {len(html_content)}")
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨JavaScriptåŠ¨æ€åŠ è½½çš„è¿¹è±¡
            if 'skeleton-loader' in html_content or 'breadcrumbs' in html_content:
                print(f"âš ï¸ æ£€æµ‹åˆ°åŠ¨æ€åŠ è½½å†…å®¹ï¼Œå°è¯•ä» URL çš„è·¯å¾„ç»“æ„æ¨æ–­å¯¼èˆª")
                return self._extract_navigation_from_url(url)
            
            # ä¼˜å…ˆä½¿ç”¨BeautifulSoupè§£æ
            try:
                from bs4 import BeautifulSoup
                soup = BeautifulSoup(html_content, 'html.parser')
                
                # å¤šç§é¢åŒ…å±‘å¯¼èˆªå…ƒç´ æŸ¥æ‰¾ç­–ç•¥
                breadcrumb_selectors = [
                    {'attrs': {'data-test-id': 'breadcrumb-nav'}},
                    {'attrs': {'aria-label': 'Breadcrumb'}},
                    {'attrs': {'class': lambda x: x and 'breadcrumb' in x.lower()}},
                    {'attrs': {'id': lambda x: x and 'breadcrumb' in x.lower()}}
                ]
                
                breadcrumb_nav = None
                for selector in breadcrumb_selectors:
                    breadcrumb_nav = soup.find('nav', selector['attrs'])
                    if breadcrumb_nav:
                        print(f"âœ… æ‰¾åˆ°é¢åŒ…å±‘å¯¼èˆªå…ƒç´ ï¼ˆä½¿ç”¨é€‰æ‹©å™¨: {selector}ï¼‰")
                        break
                
                if breadcrumb_nav:
                    return self._parse_breadcrumb_from_soup(breadcrumb_nav, url)
                else:
                    print(f"âš ï¸ BeautifulSoupæœªæ‰¾åˆ°é¢åŒ…å±‘å¯¼èˆªå…ƒç´ ")
                    
            except ImportError:
                print(f"âš ï¸ BeautifulSoupä¸å¯ç”¨ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼")
            except Exception as e:
                print(f"âŒ BeautifulSoupè§£æå¤±è´¥: {e}")
            
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼
            print(f"ğŸ”§ ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–é¢åŒ…å±‘å¯¼èˆª...")
            breadcrumb_result = self._extract_breadcrumb_with_regex(html_content, url)
            if breadcrumb_result[0]:  # å¦‚æœæ‰¾åˆ°äº†å¯¼èˆªé¡¹
                return breadcrumb_result
            
            # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆï¼šä» URL æ¨æ–­å¯¼èˆª
            print(f"ğŸ”§ ä» URL ç»“æ„æ¨æ–­å¯¼èˆªä¿¡æ¯...")
            return self._extract_navigation_from_url(url)
            
        except Exception as e:
            print(f"âŒ æå–å¯¼èˆªä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return [], ""
    
    def _extract_breadcrumb_with_regex(self, html_content: str, url: str = "") -> tuple:
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–é¢åŒ…å±‘å¯¼èˆªä¿¡æ¯ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
        try:
            import re
            
            print("ğŸ” ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å¯¼èˆªä¿¡æ¯...")
            
            breadcrumb_items = []
            navigation_parts = []
            
            # æŸ¥æ‰¾é¢åŒ…å±‘å¯¼èˆªåŒºåŸŸ
            breadcrumb_pattern = r'<nav[^>]*data-test-id="breadcrumb-nav"[^>]*>(.*?)</nav>'
            breadcrumb_match = re.search(breadcrumb_pattern, html_content, re.DOTALL | re.IGNORECASE)
            
            if not breadcrumb_match:
                print("âŒ æ­£åˆ™è¡¨è¾¾å¼æœªæ‰¾åˆ°é¢åŒ…å±‘å¯¼èˆªåŒºåŸŸ")
                return [], ""
            
            breadcrumb_html = breadcrumb_match.group(1)
            print(f"âœ… æ‰¾åˆ°é¢åŒ…å±‘å¯¼èˆªåŒºåŸŸ")
            
            # æå–å¯¼èˆªé“¾æ¥ï¼ˆæ›´ç²¾ç¡®çš„æ­£åˆ™ï¼‰
            link_pattern = r'<a[^>]*data-uds-child="breadcrumb-link"[^>]*href="([^"]*)"[^>]*>(.*?)</a>'
            links = re.findall(link_pattern, breadcrumb_html, re.DOTALL | re.IGNORECASE)
            
            for href, link_content in links:
                # æ¸…ç†é“¾æ¥å†…å®¹ï¼Œç§»é™¤HTMLæ ‡ç­¾
                clean_text = re.sub(r'<[^>]+>', '', link_content).strip()
                clean_text = re.sub(r'\s+', ' ', clean_text)  # åˆå¹¶å¤šä¸ªç©ºæ ¼
                
                if clean_text:
                    full_url = href if href.startswith('http') else f"https://us.puma.com{href}"
                    breadcrumb_items.append({
                        'text': clean_text,
                        'url': full_url,
                        'level': len(breadcrumb_items) + 1,
                        'current': False
                    })
                    navigation_parts.append(clean_text)
            
            # æå–å½“å‰é¡µé¢é¡¹ï¼ˆéé“¾æ¥é¡¹ï¼‰
            # æŸ¥æ‰¾åŒ…å« font-normal çš„ li å…ƒç´ ï¼Œä½†ä¸åŒ…å« breadcrumb-link
            current_pattern = r'<li[^>]*data-uds-child="breadcrumb-list-item"[^>]*class="[^"]*font-normal[^"]*"[^>]*>(?!.*?<a[^>]*data-uds-child="breadcrumb-link")(.*?)</li>'
            current_matches = re.findall(current_pattern, breadcrumb_html, re.DOTALL | re.IGNORECASE)
            
            if not current_matches:
                # å¤‡ç”¨æ¨¡å¼ï¼šæŸ¥æ‰¾ä¸åŒ…å«breadcrumb-linkçš„liå…ƒç´ 
                fallback_pattern = r'<li[^>]*data-uds-child="breadcrumb-list-item"[^>]*>(?!.*?<a[^>]*data-uds-child="breadcrumb-link")[^<]*([^<]+)[^<]*</li>'
                current_matches = re.findall(fallback_pattern, breadcrumb_html, re.DOTALL | re.IGNORECASE)
            
            for match in current_matches:
                clean_text = re.sub(r'<[^>]+>', '', match).strip()
                clean_text = re.sub(r'\s+', ' ', clean_text)  # åˆå¹¶å¤šä¸ªç©ºæ ¼
                
                if clean_text and clean_text not in navigation_parts and len(clean_text) > 3:
                    breadcrumb_items.append({
                        'text': clean_text,
                        'url': url or '',
                        'level': len(breadcrumb_items) + 1,
                        'current': True
                    })
                    navigation_parts.append(clean_text)
                    break  # åªå–ç¬¬ä¸€ä¸ªåŒ¹é…é¡¹
            
            # æ„å»ºå¯¼èˆªè·¯å¾„å­—ç¬¦ä¸²
            navigation_path = ' > '.join(navigation_parts)
            
            print(f"âœ… æ­£åˆ™è¡¨è¾¾å¼æå–æˆåŠŸ: {navigation_path}")
            print(f"   å¯¼èˆªé¡¹æ•°: {len(breadcrumb_items)}")
            
            for item in breadcrumb_items:
                current_flag = " (å½“å‰é¡µé¢)" if item.get('current') else ""
                print(f"     - {item['text']}{current_flag}")
            
            return breadcrumb_items, navigation_path
            
        except Exception as e:
            print(f"âŒ æ­£åˆ™è¡¨è¾¾å¼æå–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return [], ""
    
    def _parse_breadcrumb_from_soup(self, breadcrumb_nav, url: str) -> tuple:
        """ä» BeautifulSoup å¯¹è±¡ä¸­è§£æé¢åŒ…å±‘å¯¼èˆª"""
        try:
            breadcrumb_items = []
            navigation_parts = []
            
            # æå–æ‰€æœ‰å¯¼èˆªé“¾æ¥
            links = breadcrumb_nav.find_all('a', {'data-uds-child': 'breadcrumb-link'})
            
            for link in links:
                href = link.get('href', '')
                text = link.get_text(strip=True)
                
                if text:  # åŒ…æ‹¬æ‰€æœ‰é¡¹ï¼Œä¸è·³è¿‡Home
                    full_url = href if href.startswith('http') else f"https://us.puma.com{href}"
                    breadcrumb_items.append({
                        'text': text,
                        'url': full_url,
                        'level': len(breadcrumb_items) + 1,
                        'current': False
                    })
                    navigation_parts.append(text)
            
            # æå–æœ€åä¸€ä¸ªéé“¾æ¥çš„é¢åŒ…å±‘é¡¹ï¼ˆå½“å‰é¡µé¢ï¼‰
            # æŸ¥æ‰¾å…·æœ‰font-normalç±»çš„liå…ƒç´ 
            list_items = breadcrumb_nav.find_all('li', {'data-uds-child': 'breadcrumb-list-item'})
            
            for item in list_items:
                # å¦‚æœè¯¥liæ²¡æœ‰aæ ‡ç­¾ï¼Œè¯´æ˜æ˜¯å½“å‰é¡µé¢
                if not item.find('a', {'data-uds-child': 'breadcrumb-link'}):
                    current_text = item.get_text(strip=True)
                    # æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤å¤šä½™ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
                    current_text = re.sub(r'\s+', ' ', current_text).strip()
                    
                    if current_text and current_text not in navigation_parts and len(current_text) > 3:
                        breadcrumb_items.append({
                            'text': current_text,
                            'url': url,
                            'level': len(breadcrumb_items) + 1,
                            'current': True
                        })
                        navigation_parts.append(current_text)
                        break
            
            # æ„å»ºå¯¼èˆªè·¯å¾„å­—ç¬¦ä¸²
            navigation_path = ' > '.join(navigation_parts)
            
            print(f"âœ… BeautifulSoupæå–æˆåŠŸ: {navigation_path}")
            print(f"   å¯¼èˆªé¡¹æ•°: {len(breadcrumb_items)}")
            
            for item in breadcrumb_items:
                current_flag = " (å½“å‰é¡µé¢)" if item.get('current') else ""
                print(f"     - {item['text']}{current_flag}")
            
            return breadcrumb_items, navigation_path
            
        except Exception as e:
            print(f"âŒ BeautifulSoupè§£æå¤±è´¥: {e}")
            return [], ""
    
    def _extract_navigation_from_url(self, url: str) -> tuple:
        """ä» URL ç»“æ„æ¨æ–­å¯¼èˆªä¿¡æ¯ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        try:
            print(f"ğŸ”§ ä» URL ç»“æ„æ¨æ–­å¯¼èˆª: {url}")
            
            breadcrumb_items = []
            navigation_parts = []
            
            # ä» URL ä¸­è§£æä¿¡æ¯
            # ç¤ºä¾‹ URL: https://us.puma.com/us/en/pd/suede-xl-leopard-jr-youth/404299
            
            # æ·»åŠ  Home
            breadcrumb_items.append({
                'text': 'Home',
                'url': 'https://us.puma.com/us/en',
                'level': 1,
                'current': False
            })
            navigation_parts.append('Home')
            
            # æ ¹æ® URL ä¸­çš„ä¿¡æ¯æ¨æ–­åˆ†ç±»
            url_lower = url.lower()
            
            # åˆ¤æ–­ç”·å¥³ç«¥è£…
            if '/men/' in url_lower or url.endswith('/men'):
                breadcrumb_items.append({
                    'text': 'Men',
                    'url': 'https://us.puma.com/us/en/men',
                    'level': 2,
                    'current': False
                })
                navigation_parts.append('Men')
                
                # å¦‚æœæ˜¯é‹å­ç›¸å…³
                if 'shoes' in url_lower or 'sneakers' in url_lower or 'footwear' in url_lower:
                    breadcrumb_items.append({
                        'text': "Men's Shoes and Sneakers",
                        'url': 'https://us.puma.com/us/en/men/shoes',
                        'level': 3,
                        'current': False
                    })
                    navigation_parts.append("Men's Shoes and Sneakers")
                    
            elif '/women/' in url_lower or url.endswith('/women'):
                breadcrumb_items.append({
                    'text': 'Women',
                    'url': 'https://us.puma.com/us/en/women',
                    'level': 2,
                    'current': False
                })
                navigation_parts.append('Women')
                
                if 'shoes' in url_lower or 'sneakers' in url_lower or 'footwear' in url_lower:
                    breadcrumb_items.append({
                        'text': "Women's Shoes and Sneakers",
                        'url': 'https://us.puma.com/us/en/women/shoes',
                        'level': 3,
                        'current': False
                    })
                    navigation_parts.append("Women's Shoes and Sneakers")
                    
            elif '/kids/' in url_lower or 'youth' in url_lower or 'jr' in url_lower:
                breadcrumb_items.append({
                    'text': 'Kids',
                    'url': 'https://us.puma.com/us/en/kids',
                    'level': 2,
                    'current': False
                })
                navigation_parts.append('Kids')
                
                if 'shoes' in url_lower or 'sneakers' in url_lower or 'footwear' in url_lower:
                    breadcrumb_items.append({
                        'text': "Kids' Shoes and Sneakers",
                        'url': 'https://us.puma.com/us/en/kids/shoes',
                        'level': 3,
                        'current': False
                    })
                    navigation_parts.append("Kids' Shoes and Sneakers")
            
            # ä»äº§å“åç§°ä¸­æ¨æ–­å½“å‰é¡µé¢åç§°
            # æå–äº§å“åç§°ï¼ˆURL ä¸­ pd åçš„éƒ¨åˆ†ï¼‰
            import re
            product_name_match = re.search(r'/pd/([^/]+)/', url)
            if product_name_match:
                product_slug = product_name_match.group(1)
                # å°†è¿å­—ç¬¦è½¬æ¢ä¸ºç©ºæ ¼ï¼Œå¹¶å°†æ¯ä¸ªå•è¯çš„é¦–å­—æ¯å¤§å†™
                current_name = product_slug.replace('-', ' ').title()
                breadcrumb_items.append({
                    'text': current_name,
                    'url': url,
                    'level': len(breadcrumb_items) + 1,
                    'current': True
                })
                navigation_parts.append(current_name)
            
            navigation_path = ' > '.join(navigation_parts)
            
            print(f"âœ… ä» URL æ¨æ–­æˆåŠŸ: {navigation_path}")
            print(f"   å¯¼èˆªé¡¹æ•°: {len(breadcrumb_items)}")
            
            for item in breadcrumb_items:
                current_flag = " (å½“å‰é¡µé¢)" if item.get('current') else ""
                print(f"     - {item['text']}{current_flag}")
            
            return breadcrumb_items, navigation_path
            
        except Exception as e:
            print(f"âŒ URL æ¨æ–­å¤±è´¥: {e}")
            return [], ""