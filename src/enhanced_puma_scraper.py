#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–ç‰ˆå¢å¼ºPumaå•†å“ä¿¡æ¯çˆ¬è™«
"""

import requests
from bs4 import BeautifulSoup
import json
import re
from urllib.parse import urljoin
import logging
from config import get_output_path

logger = logging.getLogger(__name__)

def enhanced_scrape_puma(url):
    """
    å¢å¼ºç‰ˆPumaå•†å“çˆ¬è™«
    """
    # è®¾ç½®è¯·æ±‚å¤´
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
    }
    
    try:
        print(f"æ­£åœ¨è·å–é¡µé¢: {url}")
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        print("é¡µé¢è·å–æˆåŠŸï¼Œå¼€å§‹è§£æ...")
        
        # åˆå§‹åŒ–äº§å“ä¿¡æ¯
        product_info = {
            'name': '',
            'price': '',
            'currency': 'USD',
            'original_price': '',
            'description': '',
            'color': '',
            'brand': 'PUMA',
            'sizes': [],
            'images': [],
            'product_id': '',
            'availability': '',
            'features': [],
            'url': url
        }
        
        # æå–JSON-LDæ•°æ®
        json_data = {}
        script_tags = soup.find_all('script', type='application/ld+json')
        for script in script_tags:
            try:
                data = json.loads(script.string)
                if isinstance(data, dict) and data.get('@type') == 'Product':
                    json_data = data
                    print("æ‰¾åˆ°JSON-LDäº§å“æ•°æ®")
                    break
                elif isinstance(data, list):
                    for item in data:
                        if isinstance(item, dict) and item.get('@type') == 'Product':
                            json_data = item
                            print("æ‰¾åˆ°JSON-LDäº§å“æ•°æ®")
                            break
            except:
                continue
        
        # å•†å“åç§°
        name_selectors = [
            'h1[data-testid="pdp-product-name"]',
            'h1[data-testid="product-name"]', 
            'h1.pdp-product-name',
            'h1.product-name',
            '.product-title h1',
            'h1'
        ]
        
        for selector in name_selectors:
            element = soup.select_one(selector)
            if element and element.get_text(strip=True):
                product_info['name'] = element.get_text(strip=True)
                break
        
        # ä»JSONæ•°æ®è·å–åç§°
        if not product_info['name'] and json_data:
            product_info['name'] = json_data.get('name', '')
        
        # ä»·æ ¼ä¿¡æ¯
        price_selectors = [
            '[data-testid="current-price"]',
            '[data-testid="price"]',
            '.price-current',
            '.current-price', 
            '.price .value',
            '.pdp-price .price',
            '.price'
        ]
        
        for selector in price_selectors:
            element = soup.select_one(selector)
            if element:
                price_text = element.get_text(strip=True)
                # æå–ä»·æ ¼æ•°å­—
                price_match = re.search(r'\\$?([0-9,]+\\.?[0-9]*)', price_text)
                if price_match:
                    product_info['price'] = price_match.group(1).replace(',', '')
                    break
        
        # ä»JSONæ•°æ®è·å–ä»·æ ¼
        if not product_info['price'] and json_data:
            offers = json_data.get('offers', {})
            if isinstance(offers, dict):
                price = offers.get('price', '') or offers.get('lowPrice', '')
                if price:
                    product_info['price'] = str(price)
                    product_info['currency'] = offers.get('priceCurrency', 'USD')
        
        # å•†å“æè¿°
        desc_selectors = [
            '[data-testid="pdp-product-description"]',
            '[data-testid="product-description"]',
            '.product-description',
            '.pdp-description',
            '.description'
        ]
        
        for selector in desc_selectors:
            element = soup.select_one(selector)
            if element:
                product_info['description'] = element.get_text(strip=True)
                break
        
        # ä»JSONæ•°æ®è·å–æè¿°
        if not product_info['description'] and json_data:
            product_info['description'] = json_data.get('description', '')
        
        # é¢œè‰²ä¿¡æ¯
        color_selectors = [
            '[data-testid="color-name"]',
            '[data-testid="selected-color"]',
            '.color-name',
            '.selected-color'
        ]
        
        for selector in color_selectors:
            element = soup.select_one(selector)
            if element:
                product_info['color'] = element.get_text(strip=True)
                break
        
        # ä»URLè·å–é¢œè‰²ä»£ç 
        if not product_info['color'] and 'swatch=' in url:
            color_code = url.split('swatch=')[1].split('&')[0]
            product_info['color'] = f"Color Code: {color_code}"
        
        # äº§å“ID
        match = re.search(r'/(\\d+)(?:\\?|$)', url)
        if match:
            product_info['product_id'] = match.group(1)
        
        # å°ºç ä¿¡æ¯ - æ ¹æ®å®é™…HTMLç»“æ„æ›´æ–°é€‰æ‹©å™¨
        size_selectors = [
            '#size-picker span[data-content="size-value"]',  # ä¸»è¦é€‰æ‹©å™¨
            '[data-test-id="size-picker"] span[data-content="size-value"]',  # å¤‡ç”¨é€‰æ‹©å™¨
            '[id="size-picker"] label span[data-content="size-value"]',  # æ›´å…·ä½“çš„é€‰æ‹©å™¨
            '[data-test-id="size"] + * span[data-content="size-value"]',  # é€šè¿‡inputå…ƒç´ æŸ¥æ‰¾
            'label[data-size] span[data-content="size-value"]',  # é€šè¿‡data-sizeå±æ€§æŸ¥æ‰¾
            '[data-test-id="size-selector"] button',  # ä¿ç•™åŸæœ‰é€‰æ‹©å™¨ä½œä¸ºå¤‡ç”¨
            '.size-selector button', 
            '.sizes button', 
            '.size-option',
            'select[name*="size"] option',
            '[class*="size"] button',
            '[class*="Size"] button'
        ]
        
        print(f"ğŸ” å¼€å§‹æœç´¢å°ºç ä¿¡æ¯...")
        
        found_any_sizes = False
        for selector in size_selectors:
            elements = soup.select(selector)
            print(f"   é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(elements)} ä¸ªå…ƒç´ ")
            
            for element in elements:
                size_text = element.get_text(strip=True)
                if (size_text and len(size_text) <= 10 and 
                    size_text not in product_info['sizes'] and
                    not any(word in size_text.lower() for word in ['select', 'choose', 'guide', 'é€‰æ‹©', 'å°ºç '])):
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ç¦ç”¨çš„å°ºç ï¼ˆå¯é€‰æ‹©è®°å½•ä½†æ ‡æ³¨ä¸å¯ç”¨ï¼‰
                    parent_label = element.find_parent('label')
                    is_disabled = False
                    if parent_label:
                        is_disabled = parent_label.get('data-disabled') == 'true'
                    
                    if is_disabled:
                        size_display = f"{size_text} (ç¼ºè´§)"
                    else:
                        size_display = size_text
                    
                    product_info['sizes'].append(size_display)
                    print(f"   âœ… æ·»åŠ å°ºç : {size_display}")
                    found_any_sizes = True
        
        # å¦‚æœä¸»è¦é€‰æ‹©å™¨æ²¡æ‰¾åˆ°ï¼Œå°è¯•ç›´æ¥æŸ¥æ‰¾size-pickerå®¹å™¨
        if not found_any_sizes:
            print(f"   ğŸ” å°è¯•ç›´æ¥æŸ¥æ‰¾size-pickerå®¹å™¨...")
            size_picker = soup.find(id='size-picker')
            if not size_picker:
                size_picker = soup.find(attrs={'data-test-id': 'size-picker'})
            
            if size_picker:
                print(f"   âœ… æ‰¾åˆ°size-pickerå®¹å™¨")
                # æŸ¥æ‰¾æ‰€æœ‰labelå…ƒç´ 
                labels = size_picker.find_all('label')
                print(f"   ğŸ“‹ å®¹å™¨ä¸­æ‰¾åˆ° {len(labels)} ä¸ªå°ºç æ ‡ç­¾")
                
                for label in labels:
                    size_span = label.find('span', {'data-content': 'size-value'})
                    if size_span:
                        size_text = size_span.get_text(strip=True)
                        is_disabled = label.get('data-disabled') == 'true'
                        
                        if is_disabled:
                            size_display = f"{size_text} (ç¼ºè´§)"
                        else:
                            size_display = size_text
                        
                        if size_display not in product_info['sizes']:
                            product_info['sizes'].append(size_display)
                            print(f"   âœ… ä»å®¹å™¨æ·»åŠ å°ºç : {size_display}")
                            found_any_sizes = True
        
        # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œè¯´æ˜åŸå› 
        if not found_any_sizes:
            print(f"   âš ï¸  æœªæ‰¾åˆ°å°ºç ä¿¡æ¯ - å¯èƒ½é¡µé¢ç»“æ„å‘ç”Ÿå˜åŒ–æˆ–éœ€è¦JavaScriptæ¸²æŸ“")
        
        print(f"ğŸ‘Ÿ æ‰¾åˆ° {len(product_info['sizes'])} ä¸ªå°ºç ")
        
        # å›¾ç‰‡ä¿¡æ¯
        img_selectors = [
            '[data-testid="pdp-image-carousel"] img',
            '.product-carousel img',
            '.product-images img',
            '.image-gallery img',
            '.pdp-images img',
            'img[alt*="product"]',
            'img[class*="aspect-1-1"]',  # æ–°å¢ï¼šæ­£æ–¹å½¢å•†å“å›¾ç‰‡
            'img[alt*="evoSPEED"]',      # æ–°å¢ï¼šåŒ…å«å•†å“åçš„alt
            'img[alt*="Track"]',        # æ–°å¢ï¼šåŒ…å«Trackçš„alt
            'img[alt*="Field"]',        # æ–°å¢ï¼šåŒ…å«Fieldçš„alt
            'img[alt*="Spikes"]',       # æ–°å¢ï¼šåŒ…å«Spikesçš„alt
            'img[src*="312637"]',       # æ–°å¢ï¼šåŒ…å«å•†å“IDçš„src
            'img[src*="images.puma.com"]'  # æ–°å¢ï¼šPumaå®˜æ–¹å›¾ç‰‡CDN
        ]
        
        print(f"ğŸ” å¼€å§‹æœç´¢å•†å“å›¾ç‰‡...")
        
        for selector in img_selectors:
            images = soup.select(selector)
            print(f"   é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(images)} å¼ å›¾ç‰‡")
            
            for img in images:
                src = img.get('src') or img.get('data-src') or img.get('data-lazy-src')
                if src:
                    # æ„å»ºå®Œæ•´URL
                    if src.startswith('//'):
                        full_url = 'https:' + src
                    elif src.startswith('/'):
                        full_url = 'https://us.puma.com' + src
                    elif not src.startswith('http'):
                        full_url = urljoin('https://us.puma.com', src)
                    else:
                        full_url = src
                    
                    # è¿‡æ»¤æ— æ•ˆå›¾ç‰‡
                    if ('placeholder' not in full_url.lower() and 
                        'default' not in full_url.lower() and
                        full_url not in product_info['images'] and
                        # Pumaå›¾ç‰‡æœ‰ç‰¹æ®Šæ ¼å¼ï¼Œä¸ä½¿ç”¨ä¼ ç»Ÿæ‰©å±•å
                        'puma.com' in full_url):
                        product_info['images'].append(full_url)
                        print(f"   âœ… æ·»åŠ å›¾ç‰‡: {full_url[:80]}...")
        
        print(f"ğŸ–¼ï¸  æ€»å…±æ‰¾åˆ° {len(product_info['images'])} å¼ å•†å“å›¾ç‰‡")
        
        # äº§å“ç‰¹æ€§
        feature_selectors = [
            '.product-features li',
            '.features li',
            '.benefits li',
            '.highlights li'
        ]
        
        for selector in feature_selectors:
            elements = soup.select(selector)
            for element in elements:
                feature_text = element.get_text(strip=True)
                if feature_text and len(feature_text) > 3:
                    product_info['features'].append(feature_text)
        
        # åº“å­˜çŠ¶æ€
        availability_selectors = [
            '[data-testid="availability"]',
            '.availability',
            '.stock-status'
        ]
        
        for selector in availability_selectors:
            element = soup.select_one(selector)
            if element:
                product_info['availability'] = element.get_text(strip=True)
                break
        
        print(f"æˆåŠŸè§£æå•†å“: {product_info['name']}")
        return product_info
        
    except Exception as e:
        print(f"çˆ¬å–å¤±è´¥: {e}")
        return None


def print_product_info(product):
    """æ‰“å°å•†å“ä¿¡æ¯"""
    if not product:
        print("âŒ æ²¡æœ‰è·å–åˆ°å•†å“ä¿¡æ¯")
        return
    
    print("\\n" + "="*60)
    print("ğŸ›ï¸  å¢å¼ºç‰ˆPUMAå•†å“ä¿¡æ¯")
    print("="*60)
    print(f"ğŸ“¦ å•†å“åç§°: {product['name']}")
    print(f"ğŸ·ï¸  å“ç‰Œ: {product['brand']}")
    
    if product['price']:
        print(f"ğŸ’° ä»·æ ¼: {product['currency']} ${product['price']}")
    else:
        print("ğŸ’° ä»·æ ¼: N/A")
    
    if product['color']:
        print(f"ğŸ¨ é¢œè‰²: {product['color']}")
    
    print(f"ğŸ†” å•†å“ID: {product['product_id']}")
    
    if product['availability']:
        print(f"ğŸ“¦ åº“å­˜çŠ¶æ€: {product['availability']}")
    
    if product['sizes']:
        print(f"ğŸ‘Ÿ å¯ç”¨å°ºç  ({len(product['sizes'])}ä¸ª): {', '.join(product['sizes'][:10])}")
        if len(product['sizes']) > 10:
            print(f"    ... è¿˜æœ‰{len(product['sizes']) - 10}ä¸ªå°ºç ")
    
    print(f"ğŸ–¼ï¸  å›¾ç‰‡æ•°é‡: {len(product['images'])}å¼ ")
    
    if product['features']:
        print(f"âœ¨ äº§å“ç‰¹æ€§ ({len(product['features'])}ä¸ª):")
        for i, feature in enumerate(product['features'][:3], 1):
            print(f"   {i}. {feature}")
        if len(product['features']) > 3:
            print(f"   ... è¿˜æœ‰{len(product['features']) - 3}ä¸ªç‰¹æ€§")
    
    if product['description']:
        desc_preview = product['description'][:200] + "..." if len(product['description']) > 200 else product['description']
        print(f"ğŸ“ å•†å“æè¿°: {desc_preview}")
    
    print("="*60)


def save_to_json(product, filename="enhanced_puma_product.json"):
    """ä¿å­˜åˆ°JSONæ–‡ä»¶"""
    try:
        output_path = get_output_path(filename)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(product, f, ensure_ascii=False, indent=2)
        print(f"âœ… å•†å“ä¿¡æ¯å·²ä¿å­˜åˆ°: {output_path}")
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    url = "https://us.puma.com/us/en/pd/evospeed-mid-distance-nitro-elite-3-track--field-distance-spikes/312637?swatch=01"
    
    # çˆ¬å–å•†å“ä¿¡æ¯
    product = enhanced_scrape_puma(url)
    
    # æ˜¾ç¤ºç»“æœ
    print_product_info(product)
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    if product:
        save_to_json(product)
        
        # æ˜¾ç¤ºå›¾ç‰‡é“¾æ¥
        if product['images']:
            print(f"\\nğŸ–¼ï¸  å›¾ç‰‡é“¾æ¥ (å‰5ä¸ª):")
            for i, img in enumerate(product['images'][:5], 1):
                print(f"  {i}. {img}")


if __name__ == "__main__":
    main()